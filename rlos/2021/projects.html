<!doctype html>
<html lang="en">
  <head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="shortcut icon" type="image/x-icon" href="/assets/images/favicon.png">
  <link rel="canonical" href="/rlos/2021/projects.html" />
  <link rel="stylesheet" href="/assets/bootstrap-4.1.3-dist/css/bootstrap.min.css">
  <link rel="stylesheet" href="/assets/syntax.css">
  <link rel="stylesheet" href="/assets/main.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
  <link href="https://fonts.googleapis.com/css?family=Work+Sans:300,400,600&display=swap" rel="stylesheet">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.4.0/jquery.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.11.0/umd/popper.min.js" integrity="sha384-b/U6ypiBEHpOf/4+1nzFpr53nxSS+GLCkfwBdFNTxtclqqenISfwAzpKaMNFNmj4" crossorigin="anonymous"></script>
  <script src="/assets/app.js"></script>

  <title></title>
  <meta name="description" content="" >
</head>

  <body class=rlos>
    
    


<div class="navbar_container  main_nav_container">
  <div class="container navbar">
    <div class="logo">
      <a href="/index.html">
        <?xml version="1.0" encoding="UTF-8"?>
<svg width="172px" height="30px" viewBox="0 0 172 30" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
    <!-- Generator: Sketch 57.1 (83088) - https://sketch.com -->
    <title>logo_vw_horiz_gray</title>
    <desc>Created with Sketch.</desc>
    <g id="Styles" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
        <g id="Desktop-Copy" transform="translate(-944.000000, -314.000000)">
            <g id="logo_vw_horiz_gray" transform="translate(941.000000, 314.000000)">
                <rect id="framework" x="0" y="0" width="175" height="30"></rect>
                <path d="M49.488,22 L46.59,22 L42.252,10.12 L44.88,10.12 L47.382,17.68 L48.066,20.02 L48.732,17.698 L51.252,10.12 L53.808,10.12 L49.488,22 Z M58.524,12.82 C59.9760073,12.82 61.106996,13.2339959 61.917,14.062 C62.7270041,14.8900041 63.132,16.0359927 63.132,17.5 C63.132,18.9640073 62.7270041,20.1099959 61.917,20.938 C61.106996,21.7660041 59.9760073,22.18 58.524,22.18 C57.0719927,22.18 55.9410041,21.7660041 55.131,20.938 C54.320996,20.1099959 53.916,18.9640073 53.916,17.5 C53.916,16.0359927 54.320996,14.8900041 55.131,14.062 C55.9410041,13.2339959 57.0719927,12.82 58.524,12.82 Z M58.524,14.656 C57.8279965,14.656 57.2970018,14.8929976 56.931,15.367 C56.5649982,15.8410024 56.382,16.5519953 56.382,17.5 C56.382,18.4480047 56.5649982,19.1589976 56.931,19.633 C57.2970018,20.1070024 57.8279965,20.344 58.524,20.344 C59.2200035,20.344 59.7509982,20.1070024 60.117,19.633 C60.4830018,19.1589976 60.666,18.4480047 60.666,17.5 C60.666,16.5519953 60.4830018,15.8410024 60.117,15.367 C59.7509982,14.8929976 59.2200035,14.656 58.524,14.656 Z M79.368,13 L76.506,22 L73.644,22 L71.682,15.646 L69.792,22 L66.948,22 L64.086,13 L66.696,13 L68.496,20.02 L70.512,13 L72.942,13 L74.958,20.02 L76.758,13 L79.368,13 Z M86.316,12.82 C87.516006,12.82 88.4579966,13.2309959 89.142,14.053 C89.8260034,14.8750041 90.168,16.0179927 90.168,17.482 C90.168,18.9580074 89.8260034,20.1099959 89.142,20.938 C88.4579966,21.7660041 87.516006,22.18 86.316,22.18 C85.6679968,22.18 85.1040024,22.0330015 84.624,21.739 C84.1439976,21.4449985 83.7660014,21.0400026 83.49,20.524 L83.49,25.78 L81.024,25.78 L81.024,13 L83.202,13 L83.292,14.782 C83.5560013,14.181997 83.9489974,13.7050018 84.471,13.351 C84.9930026,12.9969982 85.6079965,12.82 86.316,12.82 Z M85.578,20.29 C86.2500034,20.29 86.7719981,20.0500024 87.144,19.57 C87.5160019,19.0899976 87.702,18.4000045 87.702,17.5 C87.702,16.5999955 87.5160019,15.9100024 87.144,15.43 C86.7719981,14.9499976 86.2500034,14.71 85.578,14.71 C84.977997,14.71 84.4920019,14.9169979 84.12,15.331 C83.7479981,15.7450021 83.5380002,16.3359962 83.49,17.104 L83.49,17.896 C83.5380002,18.6520038 83.7479981,19.2399979 84.12,19.66 C84.4920019,20.0800021 84.977997,20.29 85.578,20.29 Z M100.518,20.506 C100.770001,20.506 100.973999,20.4820002 101.13,20.434 L100.95,21.928 C100.613998,22.0960008 100.224002,22.18 99.78,22.18 C98.6279942,22.18 97.9380011,21.7300045 97.71,20.83 C97.4459987,21.2740022 97.0380028,21.6099989 96.486,21.838 C95.9339972,22.0660011 95.2800038,22.18 94.524,22.18 C93.6479956,22.18 92.9640025,21.982002 92.472,21.586 C91.9799975,21.189998 91.734,20.6200037 91.734,19.876 C91.734,18.4119927 92.9039883,17.4640022 95.244,17.032 L97.404,16.618 L97.404,16.186 C97.404,15.7059976 97.2690014,15.3250014 96.999,15.043 C96.7289987,14.7609986 96.3540024,14.62 95.874,14.62 C95.3219972,14.62 94.8720017,14.7399988 94.524,14.98 C94.1759983,15.2200012 93.9360007,15.6099973 93.804,16.15 L91.842,15.322 C92.034001,14.5419961 92.4659966,13.9300022 93.138,13.486 C93.8100034,13.0419978 94.6859946,12.82 95.766,12.82 C97.0500064,12.82 98.0519964,13.0989972 98.772,13.657 C99.4920036,14.2150028 99.852,15.0399945 99.852,16.132 L99.852,19.822 C99.852,20.0620012 99.9059995,20.2359995 100.014,20.344 C100.122001,20.4520005 100.289999,20.506 100.518,20.506 Z M95.298,20.506 C95.8260026,20.506 96.3089978,20.3770013 96.747,20.119 C97.1850022,19.8609987 97.404,19.5100022 97.404,19.066 L97.404,18.13 L95.478,18.562 C95.069998,18.6580005 94.767001,18.7869992 94.569,18.949 C94.370999,19.1110008 94.272,19.3359986 94.272,19.624 C94.272,19.9120014 94.3619991,20.1309992 94.542,20.281 C94.7220009,20.4310007 94.9739984,20.506 95.298,20.506 Z M105.054,19.138 C105.054,19.5700022 105.116999,19.8699992 105.243,20.038 C105.369001,20.2060008 105.599998,20.29 105.936,20.29 C106.140001,20.29 106.316999,20.2750001 106.467,20.245 C106.617001,20.2149998 106.793999,20.1640004 106.998,20.092 L106.782,21.802 C106.589999,21.9220006 106.338002,22.0149997 106.026,22.081 C105.713998,22.1470003 105.408002,22.18 105.108,22.18 C104.231996,22.18 103.593002,21.9670021 103.191,21.541 C102.788998,21.1149979 102.588,20.4340047 102.588,19.498 L102.588,9.058 L105.054,9.058 L105.054,19.138 Z M118.482,22 L115.62,22 L112.164,10.12 L114.846,10.12 L117.15,20.038 L119.526,10.12 L121.902,10.12 L124.314,20.038 L126.618,10.12 L129.174,10.12 L125.718,22 L122.928,22 L121.272,15.52 L120.714,12.712 L120.678,12.712 L120.12,15.52 L118.482,22 Z M138.336,20.506 C138.588001,20.506 138.791999,20.4820002 138.948,20.434 L138.768,21.928 C138.431998,22.0960008 138.042002,22.18 137.598,22.18 C136.445994,22.18 135.756001,21.7300045 135.528,20.83 C135.263999,21.2740022 134.856003,21.6099989 134.304,21.838 C133.751997,22.0660011 133.098004,22.18 132.342,22.18 C131.465996,22.18 130.782002,21.982002 130.29,21.586 C129.797998,21.189998 129.552,20.6200037 129.552,19.876 C129.552,18.4119927 130.721988,17.4640022 133.062,17.032 L135.222,16.618 L135.222,16.186 C135.222,15.7059976 135.087001,15.3250014 134.817,15.043 C134.546999,14.7609986 134.172002,14.62 133.692,14.62 C133.139997,14.62 132.690002,14.7399988 132.342,14.98 C131.993998,15.2200012 131.754001,15.6099973 131.622,16.15 L129.66,15.322 C129.852001,14.5419961 130.283997,13.9300022 130.956,13.486 C131.628003,13.0419978 132.503995,12.82 133.584,12.82 C134.868006,12.82 135.869996,13.0989972 136.59,13.657 C137.310004,14.2150028 137.67,15.0399945 137.67,16.132 L137.67,19.822 C137.67,20.0620012 137.723999,20.2359995 137.832,20.344 C137.940001,20.4520005 138.107999,20.506 138.336,20.506 Z M133.116,20.506 C133.644003,20.506 134.126998,20.3770013 134.565,20.119 C135.003002,19.8609987 135.222,19.5100022 135.222,19.066 L135.222,18.13 L133.296,18.562 C132.887998,18.6580005 132.585001,18.7869992 132.387,18.949 C132.188999,19.1110008 132.09,19.3359986 132.09,19.624 C132.09,19.9120014 132.179999,20.1309992 132.36,20.281 C132.540001,20.4310007 132.791998,20.506 133.116,20.506 Z M145.734,12.82 C146.934006,12.82 147.875997,13.2339959 148.56,14.062 C149.244003,14.8900041 149.586,16.0419926 149.586,17.518 C149.586,18.9820073 149.244003,20.1249959 148.56,20.947 C147.875997,21.7690041 146.934006,22.18 145.734,22.18 C145.025996,22.18 144.411003,22.0030018 143.889,21.649 C143.366997,21.2949982 142.974001,20.818003 142.71,20.218 L142.62,22 L140.442,22 L140.442,9.058 L142.908,9.058 L142.908,14.476 C143.184001,13.9599974 143.561998,13.5550015 144.042,13.261 C144.522002,12.9669985 145.085997,12.82 145.734,12.82 Z M144.996,20.29 C145.668003,20.29 146.189998,20.0500024 146.562,19.57 C146.934002,19.0899976 147.12,18.4000045 147.12,17.5 C147.12,16.5999955 146.934002,15.9100024 146.562,15.43 C146.189998,14.9499976 145.668003,14.71 144.996,14.71 C144.395997,14.71 143.910002,14.9199979 143.538,15.34 C143.165998,15.7600021 142.956,16.3479962 142.908,17.104 L142.908,17.896 C142.956,18.6640038 143.165998,19.2549979 143.538,19.669 C143.910002,20.0830021 144.395997,20.29 144.996,20.29 Z M157.056,12.82 C158.256006,12.82 159.197997,13.2339959 159.882,14.062 C160.566003,14.8900041 160.908,16.0419926 160.908,17.518 C160.908,18.9820073 160.566003,20.1249959 159.882,20.947 C159.197997,21.7690041 158.256006,22.18 157.056,22.18 C156.347996,22.18 155.733003,22.0030018 155.211,21.649 C154.688997,21.2949982 154.296001,20.818003 154.032,20.218 L153.942,22 L151.764,22 L151.764,9.058 L154.23,9.058 L154.23,14.476 C154.506001,13.9599974 154.883998,13.5550015 155.364,13.261 C155.844002,12.9669985 156.407997,12.82 157.056,12.82 Z M156.318,20.29 C156.990003,20.29 157.511998,20.0500024 157.884,19.57 C158.256002,19.0899976 158.442,18.4000045 158.442,17.5 C158.442,16.5999955 158.256002,15.9100024 157.884,15.43 C157.511998,14.9499976 156.990003,14.71 156.318,14.71 C155.717997,14.71 155.232002,14.9199979 154.86,15.34 C154.487998,15.7600021 154.278,16.3479962 154.23,17.104 L154.23,17.896 C154.278,18.6640038 154.487998,19.2549979 154.86,19.669 C155.232002,20.0830021 155.717997,20.29 156.318,20.29 Z M164.328,11.704 C163.307995,11.704 162.798,11.2660044 162.798,10.39 C162.798,9.50199556 163.307995,9.058 164.328,9.058 C165.348005,9.058 165.858,9.50199556 165.858,10.39 C165.858,11.2660044 165.348005,11.704 164.328,11.704 Z M165.552,22 L163.086,22 L163.086,13 L165.552,13 L165.552,22 Z M174.336,21.442 C174.047999,21.6700011 173.685002,21.8499993 173.247,21.982 C172.808998,22.1140007 172.350002,22.18 171.87,22.18 C169.86599,22.18 168.864,21.2740091 168.864,19.462 L168.864,14.836 L167.226,14.836 L167.226,13 L168.864,13 L168.864,10.93 L171.33,10.246 L171.33,13 L174.246,13 L174.246,14.836 L171.33,14.836 L171.33,19.066 C171.33,19.8940041 171.743996,20.308 172.572,20.308 C173.100003,20.308 173.561998,20.1400017 173.958,19.804 L174.336,21.442 Z" id="VowpalWabbit" fill="#333333" fill-rule="nonzero"></path>
                <g id="logo_vw_color" transform="translate(3.000000, 0.000000)" fill="#2A3B93">
                    <path d="M27.9875518,16.6117194 C27.9875518,9.21947752 21.9666728,9.36035971 21.9666728,9.36035971 C21.3736977,6.15536974 20.3362508,3.5963294 19.3414955,1.96947553 C18.1790857,0.436543115 17.3241355,0 17.3241355,0 C16.2887633,0.700737156 15.7766231,3.93943024 15.7766231,3.93943024 C14.1726939,1.18184505 12.329851,1.05294263 12.329851,1.05294263 C9.93824094,8.37466357 17.0427696,11.1203489 17.0427696,11.1203489 C9.97542657,11.1203489 6.33307087,15.0400524 4.59284756,17.9877167 C4.0042614,19.0524794 3.60319929,20.0302689 3.35048069,20.7371557 L2.99801525,21.8605394 C1.89952322,21.2108361 0.011355398,21.1878349 0.011355398,21.1878349 C-0.278708419,29.2136474 5.0845596,28.0167877 5.0845596,28.0167877 C5.0845596,29.1432063 6.56177043,30 6.56177043,30 L18.0978518,30 C18.0978518,30 17.9248509,28.5478912 16.7183131,27.7616983 C16.5196972,27.4693917 16.4533057,27.212705 16.6897456,26.9422016 C17.354698,26.1816454 17.8296525,27.1798804 17.8296525,27.1798804 L18.3302221,27.8553801 C19.7539686,29.627988 20.7440159,29.9516816 21.1646284,30 L21.391732,30 C20.5763614,27.5009384 20.6054875,25.3190215 20.6054875,25.3190215 C20.4822802,22.1365535 22.8107704,19.2166024 22.8107704,19.2166024 C28.5084697,19.2166024 27.9875518,16.6117194 27.9875518,16.6117194" id="logo_rabbit"></path>
                </g>
            </g>
        </g>
    </g>
</svg>
      </a>
    </div>

    <div class="nav">
      <a
        href="/start.html"
        class=''
      >
        Get started
      </a>
      <a
        href="/features.html"
        class=''
      >
        Features
      </a>
      <a
        href="/tutorials.html"
        class=''
      >
        Tutorials
      </a>
      <a
        href="/blog.html"
        class=''
      >
        Blog
      </a>
      <a
        href="/research.html"
        class=''
      >
        Research
      </a>
      <div class="external_links">
        <a href="https://vowpalwabbit.org/docs/vowpal_wabbit/python/latest/index.html">
          Doc
        </a>

        <a
          href="https://github.com/VowpalWabbit/vowpal_wabbit/wiki"
          target="_blank"
        >
          Wiki
        </a>

        <a
          href="https://github.com/VowpalWabbit/vowpal_wabbit"
          target="_blank"
          class="github_link"
        >
          <?xml version="1.0" encoding="UTF-8"?>
<svg width="30px" height="30px" viewBox="0 0 30 30" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
    <!-- Generator: Sketch 53 (72520) - https://sketchapp.com -->
    <title>GitHub</title>
    <desc>Created with Sketch.</desc>
    <g id="Symbols" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
        <g id="HD_Desktop_header_Home" transform="translate(-1538.000000, -58.000000)" fill="#FFFFFF">
            <g id="Header">
                <path d="M1568,73.7951128 C1567.94603,74.2583723 1567.89891,74.7224863 1567.83682,75.1847206 C1567.56271,77.2238487 1566.86543,79.1138828 1565.7732,80.8526868 C1564.55268,82.7956941 1562.9969,84.4188114 1561.05088,85.6538569 C1560.03339,86.2996179 1558.94817,86.8066231 1557.80753,87.1895684 C1557.17559,87.4016322 1556.73848,87.0743943 1556.73531,86.4093237 C1556.72907,85.1020808 1556.73745,83.7947524 1556.73164,82.487424 C1556.72804,81.6908602 1556.64825,80.9063436 1556.21259,80.2087201 C1556.0855,80.0052003 1555.92463,79.8226135 1555.77393,79.6234512 C1556.35935,79.5140871 1556.9463,79.4362506 1557.51632,79.2916849 C1559.04696,78.9034423 1560.41543,78.2275208 1561.34791,76.8924242 C1562.03287,75.9115647 1562.34632,74.7851144 1562.48436,73.6108172 C1562.59169,72.6982249 1562.62222,71.7826422 1562.42971,70.8740656 C1562.23608,69.9599354 1561.84044,69.1418405 1561.22834,68.4359293 C1561.07756,68.2620575 1561.04763,68.1215929 1561.12221,67.896713 C1561.52468,66.6818314 1561.3562,65.491984 1560.9042,64.3262309 C1560.87829,64.2595017 1560.76574,64.1973008 1560.68569,64.1853391 C1560.15364,64.1058793 1559.65196,64.2559986 1559.18533,64.4761793 C1558.42904,64.8332361 1557.69764,65.242668 1556.9487,65.6159585 C1556.82229,65.6790137 1556.64782,65.7219904 1556.51706,65.6889249 C1554.16941,65.0964789 1551.82595,65.097077 1549.47805,65.6883268 C1549.34078,65.7228448 1549.14638,65.677134 1549.02331,65.5987849 C1548.07109,64.9919849 1547.06446,64.5120644 1545.97001,64.2236166 C1545.9511,64.218661 1545.93272,64.2115694 1545.91364,64.2077246 C1545.22551,64.0670892 1545.09971,64.1456947 1544.9036,64.8108506 C1544.58682,65.884755 1544.5296,66.9550708 1544.90668,68.0296587 C1544.93627,68.1139033 1544.90129,68.2616303 1544.8404,68.3306664 C1543.60397,69.7341156 1543.31096,71.3989279 1543.46559,73.1936101 C1543.55933,74.2817831 1543.81162,75.3262104 1544.29869,76.3083514 C1544.97176,77.6654063 1546.11181,78.4952066 1547.4926,78.982475 C1548.35956,79.2884382 1549.27852,79.4473579 1550.18824,79.6758264 C1550.19526,79.6319098 1550.20056,79.6666842 1550.18568,79.6820635 C1549.71726,80.1697591 1549.45556,80.755028 1549.34531,81.4170227 C1549.33137,81.5007546 1549.27365,81.6203716 1549.20685,81.6454912 C1548.16482,82.0372369 1547.11706,82.2433199 1546.08683,81.6149888 C1545.61867,81.3295314 1545.27683,80.9169382 1545.00101,80.4479541 C1544.56852,79.712395 1543.95864,79.179074 1543.13923,78.9361661 C1542.84434,78.8487602 1542.50823,78.8709748 1542.19359,78.8892591 C1541.97909,78.9018189 1541.90862,79.062362 1542.05256,79.2422147 C1542.18529,79.4077988 1542.32025,79.5950849 1542.4978,79.6971865 C1543.28625,80.1507913 1543.72798,80.8753286 1544.08881,81.6641173 C1544.30382,82.1341266 1544.48812,82.6140471 1544.88675,82.9753759 C1545.52169,83.5510755 1546.29115,83.7682658 1547.11612,83.8044072 C1547.81434,83.834995 1548.51496,83.8107298 1549.24722,83.8107298 C1549.24611,83.8009041 1549.26073,83.8742123 1549.26167,83.9476058 C1549.27211,84.7377616 1549.2828,85.5279173 1549.28844,86.3180731 C1549.294,87.0913115 1548.82935,87.4109452 1548.0952,87.1563319 C1544.28705,85.8355039 1541.4928,83.3342269 1539.62819,79.7992882 C1538.22405,77.1372118 1537.78027,74.2780237 1538.09739,71.2935795 C1538.4294,68.1688416 1539.66702,65.4337134 1541.73193,63.0872551 C1543.89022,60.6347648 1546.57714,59.0045559 1549.78825,58.3523869 C1554.45335,57.4048494 1558.71409,58.3562318 1562.44442,61.3515269 C1565.27245,63.6222848 1567.02271,66.5767393 1567.72914,70.1361141 C1567.83314,70.6605492 1567.87265,71.197715 1567.94398,71.7286436 C1567.95792,71.832625 1567.9811,71.9354102 1568,72.0387934 L1568,73.7951128 Z" id="GitHub"></path>
            </g>
        </g>
    </g>
</svg>
          <div>
            GitHub
          </div>
        </a>
      </div>
    </div>
  </div>
</div>




<div class="navbar_container  mobile_nav_container">
  <div class="container navbar">
    <div class="hamburger_icon">
      <?xml version="1.0" encoding="UTF-8"?>
<svg width="18px" height="16px" viewBox="0 0 18 16" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
    <!-- Generator: sketchtool 57.1 (101010) - https://sketch.com -->
    <title>8049A6A1-2687-43E9-9B5D-E205E8F9E871</title>
    <desc>Created with sketchtool.</desc>
    <g id="Pages" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd" stroke-linecap="round">
        <g id="Mobile_home" transform="translate(-12.000000, -56.000000)" stroke="#FFFFFF" stroke-width="2">
            <g id="header">
                <g id="ui_header_mobile_dk" transform="translate(12.000000, 44.000000)">
                    <g id="icon_menu" transform="translate(1.000000, 12.500000)">
                        <g id="Line">
                            <path d="M16,0.5 L0,0.5"></path>
                            <path d="M16,7.5 L0,7.5"></path>
                            <path d="M16,14.5 L0,14.5"></path>
                        </g>
                    </g>
                </g>
            </g>
        </g>
    </g>
</svg>
    </div>
    <div class="logo">
      <a href="/index.html">
        <?xml version="1.0" encoding="UTF-8"?>
<svg width="172px" height="30px" viewBox="0 0 172 30" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
    <!-- Generator: Sketch 57.1 (83088) - https://sketch.com -->
    <title>logo_vw_horiz_gray</title>
    <desc>Created with Sketch.</desc>
    <g id="Styles" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
        <g id="Desktop-Copy" transform="translate(-944.000000, -314.000000)">
            <g id="logo_vw_horiz_gray" transform="translate(941.000000, 314.000000)">
                <rect id="framework" x="0" y="0" width="175" height="30"></rect>
                <path d="M49.488,22 L46.59,22 L42.252,10.12 L44.88,10.12 L47.382,17.68 L48.066,20.02 L48.732,17.698 L51.252,10.12 L53.808,10.12 L49.488,22 Z M58.524,12.82 C59.9760073,12.82 61.106996,13.2339959 61.917,14.062 C62.7270041,14.8900041 63.132,16.0359927 63.132,17.5 C63.132,18.9640073 62.7270041,20.1099959 61.917,20.938 C61.106996,21.7660041 59.9760073,22.18 58.524,22.18 C57.0719927,22.18 55.9410041,21.7660041 55.131,20.938 C54.320996,20.1099959 53.916,18.9640073 53.916,17.5 C53.916,16.0359927 54.320996,14.8900041 55.131,14.062 C55.9410041,13.2339959 57.0719927,12.82 58.524,12.82 Z M58.524,14.656 C57.8279965,14.656 57.2970018,14.8929976 56.931,15.367 C56.5649982,15.8410024 56.382,16.5519953 56.382,17.5 C56.382,18.4480047 56.5649982,19.1589976 56.931,19.633 C57.2970018,20.1070024 57.8279965,20.344 58.524,20.344 C59.2200035,20.344 59.7509982,20.1070024 60.117,19.633 C60.4830018,19.1589976 60.666,18.4480047 60.666,17.5 C60.666,16.5519953 60.4830018,15.8410024 60.117,15.367 C59.7509982,14.8929976 59.2200035,14.656 58.524,14.656 Z M79.368,13 L76.506,22 L73.644,22 L71.682,15.646 L69.792,22 L66.948,22 L64.086,13 L66.696,13 L68.496,20.02 L70.512,13 L72.942,13 L74.958,20.02 L76.758,13 L79.368,13 Z M86.316,12.82 C87.516006,12.82 88.4579966,13.2309959 89.142,14.053 C89.8260034,14.8750041 90.168,16.0179927 90.168,17.482 C90.168,18.9580074 89.8260034,20.1099959 89.142,20.938 C88.4579966,21.7660041 87.516006,22.18 86.316,22.18 C85.6679968,22.18 85.1040024,22.0330015 84.624,21.739 C84.1439976,21.4449985 83.7660014,21.0400026 83.49,20.524 L83.49,25.78 L81.024,25.78 L81.024,13 L83.202,13 L83.292,14.782 C83.5560013,14.181997 83.9489974,13.7050018 84.471,13.351 C84.9930026,12.9969982 85.6079965,12.82 86.316,12.82 Z M85.578,20.29 C86.2500034,20.29 86.7719981,20.0500024 87.144,19.57 C87.5160019,19.0899976 87.702,18.4000045 87.702,17.5 C87.702,16.5999955 87.5160019,15.9100024 87.144,15.43 C86.7719981,14.9499976 86.2500034,14.71 85.578,14.71 C84.977997,14.71 84.4920019,14.9169979 84.12,15.331 C83.7479981,15.7450021 83.5380002,16.3359962 83.49,17.104 L83.49,17.896 C83.5380002,18.6520038 83.7479981,19.2399979 84.12,19.66 C84.4920019,20.0800021 84.977997,20.29 85.578,20.29 Z M100.518,20.506 C100.770001,20.506 100.973999,20.4820002 101.13,20.434 L100.95,21.928 C100.613998,22.0960008 100.224002,22.18 99.78,22.18 C98.6279942,22.18 97.9380011,21.7300045 97.71,20.83 C97.4459987,21.2740022 97.0380028,21.6099989 96.486,21.838 C95.9339972,22.0660011 95.2800038,22.18 94.524,22.18 C93.6479956,22.18 92.9640025,21.982002 92.472,21.586 C91.9799975,21.189998 91.734,20.6200037 91.734,19.876 C91.734,18.4119927 92.9039883,17.4640022 95.244,17.032 L97.404,16.618 L97.404,16.186 C97.404,15.7059976 97.2690014,15.3250014 96.999,15.043 C96.7289987,14.7609986 96.3540024,14.62 95.874,14.62 C95.3219972,14.62 94.8720017,14.7399988 94.524,14.98 C94.1759983,15.2200012 93.9360007,15.6099973 93.804,16.15 L91.842,15.322 C92.034001,14.5419961 92.4659966,13.9300022 93.138,13.486 C93.8100034,13.0419978 94.6859946,12.82 95.766,12.82 C97.0500064,12.82 98.0519964,13.0989972 98.772,13.657 C99.4920036,14.2150028 99.852,15.0399945 99.852,16.132 L99.852,19.822 C99.852,20.0620012 99.9059995,20.2359995 100.014,20.344 C100.122001,20.4520005 100.289999,20.506 100.518,20.506 Z M95.298,20.506 C95.8260026,20.506 96.3089978,20.3770013 96.747,20.119 C97.1850022,19.8609987 97.404,19.5100022 97.404,19.066 L97.404,18.13 L95.478,18.562 C95.069998,18.6580005 94.767001,18.7869992 94.569,18.949 C94.370999,19.1110008 94.272,19.3359986 94.272,19.624 C94.272,19.9120014 94.3619991,20.1309992 94.542,20.281 C94.7220009,20.4310007 94.9739984,20.506 95.298,20.506 Z M105.054,19.138 C105.054,19.5700022 105.116999,19.8699992 105.243,20.038 C105.369001,20.2060008 105.599998,20.29 105.936,20.29 C106.140001,20.29 106.316999,20.2750001 106.467,20.245 C106.617001,20.2149998 106.793999,20.1640004 106.998,20.092 L106.782,21.802 C106.589999,21.9220006 106.338002,22.0149997 106.026,22.081 C105.713998,22.1470003 105.408002,22.18 105.108,22.18 C104.231996,22.18 103.593002,21.9670021 103.191,21.541 C102.788998,21.1149979 102.588,20.4340047 102.588,19.498 L102.588,9.058 L105.054,9.058 L105.054,19.138 Z M118.482,22 L115.62,22 L112.164,10.12 L114.846,10.12 L117.15,20.038 L119.526,10.12 L121.902,10.12 L124.314,20.038 L126.618,10.12 L129.174,10.12 L125.718,22 L122.928,22 L121.272,15.52 L120.714,12.712 L120.678,12.712 L120.12,15.52 L118.482,22 Z M138.336,20.506 C138.588001,20.506 138.791999,20.4820002 138.948,20.434 L138.768,21.928 C138.431998,22.0960008 138.042002,22.18 137.598,22.18 C136.445994,22.18 135.756001,21.7300045 135.528,20.83 C135.263999,21.2740022 134.856003,21.6099989 134.304,21.838 C133.751997,22.0660011 133.098004,22.18 132.342,22.18 C131.465996,22.18 130.782002,21.982002 130.29,21.586 C129.797998,21.189998 129.552,20.6200037 129.552,19.876 C129.552,18.4119927 130.721988,17.4640022 133.062,17.032 L135.222,16.618 L135.222,16.186 C135.222,15.7059976 135.087001,15.3250014 134.817,15.043 C134.546999,14.7609986 134.172002,14.62 133.692,14.62 C133.139997,14.62 132.690002,14.7399988 132.342,14.98 C131.993998,15.2200012 131.754001,15.6099973 131.622,16.15 L129.66,15.322 C129.852001,14.5419961 130.283997,13.9300022 130.956,13.486 C131.628003,13.0419978 132.503995,12.82 133.584,12.82 C134.868006,12.82 135.869996,13.0989972 136.59,13.657 C137.310004,14.2150028 137.67,15.0399945 137.67,16.132 L137.67,19.822 C137.67,20.0620012 137.723999,20.2359995 137.832,20.344 C137.940001,20.4520005 138.107999,20.506 138.336,20.506 Z M133.116,20.506 C133.644003,20.506 134.126998,20.3770013 134.565,20.119 C135.003002,19.8609987 135.222,19.5100022 135.222,19.066 L135.222,18.13 L133.296,18.562 C132.887998,18.6580005 132.585001,18.7869992 132.387,18.949 C132.188999,19.1110008 132.09,19.3359986 132.09,19.624 C132.09,19.9120014 132.179999,20.1309992 132.36,20.281 C132.540001,20.4310007 132.791998,20.506 133.116,20.506 Z M145.734,12.82 C146.934006,12.82 147.875997,13.2339959 148.56,14.062 C149.244003,14.8900041 149.586,16.0419926 149.586,17.518 C149.586,18.9820073 149.244003,20.1249959 148.56,20.947 C147.875997,21.7690041 146.934006,22.18 145.734,22.18 C145.025996,22.18 144.411003,22.0030018 143.889,21.649 C143.366997,21.2949982 142.974001,20.818003 142.71,20.218 L142.62,22 L140.442,22 L140.442,9.058 L142.908,9.058 L142.908,14.476 C143.184001,13.9599974 143.561998,13.5550015 144.042,13.261 C144.522002,12.9669985 145.085997,12.82 145.734,12.82 Z M144.996,20.29 C145.668003,20.29 146.189998,20.0500024 146.562,19.57 C146.934002,19.0899976 147.12,18.4000045 147.12,17.5 C147.12,16.5999955 146.934002,15.9100024 146.562,15.43 C146.189998,14.9499976 145.668003,14.71 144.996,14.71 C144.395997,14.71 143.910002,14.9199979 143.538,15.34 C143.165998,15.7600021 142.956,16.3479962 142.908,17.104 L142.908,17.896 C142.956,18.6640038 143.165998,19.2549979 143.538,19.669 C143.910002,20.0830021 144.395997,20.29 144.996,20.29 Z M157.056,12.82 C158.256006,12.82 159.197997,13.2339959 159.882,14.062 C160.566003,14.8900041 160.908,16.0419926 160.908,17.518 C160.908,18.9820073 160.566003,20.1249959 159.882,20.947 C159.197997,21.7690041 158.256006,22.18 157.056,22.18 C156.347996,22.18 155.733003,22.0030018 155.211,21.649 C154.688997,21.2949982 154.296001,20.818003 154.032,20.218 L153.942,22 L151.764,22 L151.764,9.058 L154.23,9.058 L154.23,14.476 C154.506001,13.9599974 154.883998,13.5550015 155.364,13.261 C155.844002,12.9669985 156.407997,12.82 157.056,12.82 Z M156.318,20.29 C156.990003,20.29 157.511998,20.0500024 157.884,19.57 C158.256002,19.0899976 158.442,18.4000045 158.442,17.5 C158.442,16.5999955 158.256002,15.9100024 157.884,15.43 C157.511998,14.9499976 156.990003,14.71 156.318,14.71 C155.717997,14.71 155.232002,14.9199979 154.86,15.34 C154.487998,15.7600021 154.278,16.3479962 154.23,17.104 L154.23,17.896 C154.278,18.6640038 154.487998,19.2549979 154.86,19.669 C155.232002,20.0830021 155.717997,20.29 156.318,20.29 Z M164.328,11.704 C163.307995,11.704 162.798,11.2660044 162.798,10.39 C162.798,9.50199556 163.307995,9.058 164.328,9.058 C165.348005,9.058 165.858,9.50199556 165.858,10.39 C165.858,11.2660044 165.348005,11.704 164.328,11.704 Z M165.552,22 L163.086,22 L163.086,13 L165.552,13 L165.552,22 Z M174.336,21.442 C174.047999,21.6700011 173.685002,21.8499993 173.247,21.982 C172.808998,22.1140007 172.350002,22.18 171.87,22.18 C169.86599,22.18 168.864,21.2740091 168.864,19.462 L168.864,14.836 L167.226,14.836 L167.226,13 L168.864,13 L168.864,10.93 L171.33,10.246 L171.33,13 L174.246,13 L174.246,14.836 L171.33,14.836 L171.33,19.066 C171.33,19.8940041 171.743996,20.308 172.572,20.308 C173.100003,20.308 173.561998,20.1400017 173.958,19.804 L174.336,21.442 Z" id="VowpalWabbit" fill="#333333" fill-rule="nonzero"></path>
                <g id="logo_vw_color" transform="translate(3.000000, 0.000000)" fill="#2A3B93">
                    <path d="M27.9875518,16.6117194 C27.9875518,9.21947752 21.9666728,9.36035971 21.9666728,9.36035971 C21.3736977,6.15536974 20.3362508,3.5963294 19.3414955,1.96947553 C18.1790857,0.436543115 17.3241355,0 17.3241355,0 C16.2887633,0.700737156 15.7766231,3.93943024 15.7766231,3.93943024 C14.1726939,1.18184505 12.329851,1.05294263 12.329851,1.05294263 C9.93824094,8.37466357 17.0427696,11.1203489 17.0427696,11.1203489 C9.97542657,11.1203489 6.33307087,15.0400524 4.59284756,17.9877167 C4.0042614,19.0524794 3.60319929,20.0302689 3.35048069,20.7371557 L2.99801525,21.8605394 C1.89952322,21.2108361 0.011355398,21.1878349 0.011355398,21.1878349 C-0.278708419,29.2136474 5.0845596,28.0167877 5.0845596,28.0167877 C5.0845596,29.1432063 6.56177043,30 6.56177043,30 L18.0978518,30 C18.0978518,30 17.9248509,28.5478912 16.7183131,27.7616983 C16.5196972,27.4693917 16.4533057,27.212705 16.6897456,26.9422016 C17.354698,26.1816454 17.8296525,27.1798804 17.8296525,27.1798804 L18.3302221,27.8553801 C19.7539686,29.627988 20.7440159,29.9516816 21.1646284,30 L21.391732,30 C20.5763614,27.5009384 20.6054875,25.3190215 20.6054875,25.3190215 C20.4822802,22.1365535 22.8107704,19.2166024 22.8107704,19.2166024 C28.5084697,19.2166024 27.9875518,16.6117194 27.9875518,16.6117194" id="logo_rabbit"></path>
                </g>
            </g>
        </g>
    </g>
</svg>
      </a>
    </div>
  </div>
</div>

<div class="mobile_nav">
  <button type="button" class="go_back_button">
    <
  </button>

  <a href="/start.html" class=''>
    Get started
  </a>
  <a
    href="/features.html"
    class=''
  >
    Features
  </a>
  <a href="/tutorials.html" class=''>
    Tutorials
  </a>
  <a
    href="/blog.html"
    class=''
  >
    Blog
  </a>
  <a href="/research.html" class=''>
    Research
  </a>
  <div class="external_links">
    <a
      href="https://github.com/VowpalWabbit/vowpalwabbit.github.io/issues/new"
      target="_blank"
    >
      Feedback
    </a>

    <a href="https://vowpalwabbit.org/docs/vowpal_wabbit/python/latest/index.html">
      Doc
    </a>

    <a href="https://github.com/VowpalWabbit/vowpal_wabbit/wiki" target="_blank">
      Wiki
    </a>

    <a href="https://github.com/VowpalWabbit/vowpal_wabbit" target="_blank" class="github_link">
      <?xml version="1.0" encoding="UTF-8"?>
<svg width="30px" height="30px" viewBox="0 0 30 30" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
    <!-- Generator: Sketch 53 (72520) - https://sketchapp.com -->
    <title>GitHub</title>
    <desc>Created with Sketch.</desc>
    <g id="Symbols" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
        <g id="HD_Desktop_header_Home" transform="translate(-1538.000000, -58.000000)" fill="#FFFFFF">
            <g id="Header">
                <path d="M1568,73.7951128 C1567.94603,74.2583723 1567.89891,74.7224863 1567.83682,75.1847206 C1567.56271,77.2238487 1566.86543,79.1138828 1565.7732,80.8526868 C1564.55268,82.7956941 1562.9969,84.4188114 1561.05088,85.6538569 C1560.03339,86.2996179 1558.94817,86.8066231 1557.80753,87.1895684 C1557.17559,87.4016322 1556.73848,87.0743943 1556.73531,86.4093237 C1556.72907,85.1020808 1556.73745,83.7947524 1556.73164,82.487424 C1556.72804,81.6908602 1556.64825,80.9063436 1556.21259,80.2087201 C1556.0855,80.0052003 1555.92463,79.8226135 1555.77393,79.6234512 C1556.35935,79.5140871 1556.9463,79.4362506 1557.51632,79.2916849 C1559.04696,78.9034423 1560.41543,78.2275208 1561.34791,76.8924242 C1562.03287,75.9115647 1562.34632,74.7851144 1562.48436,73.6108172 C1562.59169,72.6982249 1562.62222,71.7826422 1562.42971,70.8740656 C1562.23608,69.9599354 1561.84044,69.1418405 1561.22834,68.4359293 C1561.07756,68.2620575 1561.04763,68.1215929 1561.12221,67.896713 C1561.52468,66.6818314 1561.3562,65.491984 1560.9042,64.3262309 C1560.87829,64.2595017 1560.76574,64.1973008 1560.68569,64.1853391 C1560.15364,64.1058793 1559.65196,64.2559986 1559.18533,64.4761793 C1558.42904,64.8332361 1557.69764,65.242668 1556.9487,65.6159585 C1556.82229,65.6790137 1556.64782,65.7219904 1556.51706,65.6889249 C1554.16941,65.0964789 1551.82595,65.097077 1549.47805,65.6883268 C1549.34078,65.7228448 1549.14638,65.677134 1549.02331,65.5987849 C1548.07109,64.9919849 1547.06446,64.5120644 1545.97001,64.2236166 C1545.9511,64.218661 1545.93272,64.2115694 1545.91364,64.2077246 C1545.22551,64.0670892 1545.09971,64.1456947 1544.9036,64.8108506 C1544.58682,65.884755 1544.5296,66.9550708 1544.90668,68.0296587 C1544.93627,68.1139033 1544.90129,68.2616303 1544.8404,68.3306664 C1543.60397,69.7341156 1543.31096,71.3989279 1543.46559,73.1936101 C1543.55933,74.2817831 1543.81162,75.3262104 1544.29869,76.3083514 C1544.97176,77.6654063 1546.11181,78.4952066 1547.4926,78.982475 C1548.35956,79.2884382 1549.27852,79.4473579 1550.18824,79.6758264 C1550.19526,79.6319098 1550.20056,79.6666842 1550.18568,79.6820635 C1549.71726,80.1697591 1549.45556,80.755028 1549.34531,81.4170227 C1549.33137,81.5007546 1549.27365,81.6203716 1549.20685,81.6454912 C1548.16482,82.0372369 1547.11706,82.2433199 1546.08683,81.6149888 C1545.61867,81.3295314 1545.27683,80.9169382 1545.00101,80.4479541 C1544.56852,79.712395 1543.95864,79.179074 1543.13923,78.9361661 C1542.84434,78.8487602 1542.50823,78.8709748 1542.19359,78.8892591 C1541.97909,78.9018189 1541.90862,79.062362 1542.05256,79.2422147 C1542.18529,79.4077988 1542.32025,79.5950849 1542.4978,79.6971865 C1543.28625,80.1507913 1543.72798,80.8753286 1544.08881,81.6641173 C1544.30382,82.1341266 1544.48812,82.6140471 1544.88675,82.9753759 C1545.52169,83.5510755 1546.29115,83.7682658 1547.11612,83.8044072 C1547.81434,83.834995 1548.51496,83.8107298 1549.24722,83.8107298 C1549.24611,83.8009041 1549.26073,83.8742123 1549.26167,83.9476058 C1549.27211,84.7377616 1549.2828,85.5279173 1549.28844,86.3180731 C1549.294,87.0913115 1548.82935,87.4109452 1548.0952,87.1563319 C1544.28705,85.8355039 1541.4928,83.3342269 1539.62819,79.7992882 C1538.22405,77.1372118 1537.78027,74.2780237 1538.09739,71.2935795 C1538.4294,68.1688416 1539.66702,65.4337134 1541.73193,63.0872551 C1543.89022,60.6347648 1546.57714,59.0045559 1549.78825,58.3523869 C1554.45335,57.4048494 1558.71409,58.3562318 1562.44442,61.3515269 C1565.27245,63.6222848 1567.02271,66.5767393 1567.72914,70.1361141 C1567.83314,70.6605492 1567.87265,71.197715 1567.94398,71.7286436 C1567.95792,71.832625 1567.9811,71.9354102 1568,72.0387934 L1568,73.7951128 Z" id="GitHub"></path>
            </g>
        </g>
    </g>
</svg>
      <div>
        GitHub
      </div>
    </a>
  </div>
</div>

<script src="/assets/js/header.js"></script>

    
    <div class="content">
      <div class="hero">
        <div class="container">
          <div class="row">
            <div class="col-lg-6">
              <h1>
                2021 Projects
              </h1>
            </div>
          </div>
        </div>
      </div>
    
      <div class="container content tutorial_container">
        <div class="row">
          <div class="col-lg-3">
            <div class="tutorial_nav">
              <ul class="tutorial_content_nav">
                <li class="label">
                  Table of contents
                </li>
              </ul>
            </div>
          </div>
          <div class="col-lg-9">
            <h1 id="rlopen-source-fest-projects">RL Open Source Fest Projects</h1>

<p>See <a href="/rlos/2020/projects.html">here</a> for last year’s projects.</p>

<h2 id="1-raspberry-wabbit">1. Raspberry Wabbit</h2>
<p>Recent Raspberry Pi boards are more than powerful enough to run VW for online RL learning on device. However, ssome infrastructure work would facilitate mass adoption. This project would perform this infrastructure work and provide a demo application.</p>

<h3 id="goals">Goals</h3>
<ul>
  <li>Support for audio and video featurization for VW
    <ul>
      <li>Support at least one audio and one video device</li>
      <li>Support NPU featurization</li>
    </ul>
  </li>
  <li>Virtual kit
    <ul>
      <li>Docker container and boot image containing all code ready to go</li>
      <li>Links to buy all associated hardware</li>
      <li>Nicely documented hello world instructions</li>
    </ul>
  </li>
</ul>

<h3 id="stretch-goals">Stretch goals</h3>
<ul>
  <li>Canonical closed-loop application
    <ul>
      <li>Support for actions, GPIO or networked actuator</li>
      <li>Support for feedback, e.g., GPIO or networked sensor, Fitbit, etc</li>
    </ul>
  </li>
</ul>

<h2 id="2-python-support-for-variable-and-model-introspection">2. Python support for variable and model introspection</h2>
<p>Understanding how model variables influence predictions helps both troubleshooting and gaining insights into ones dataset. This project aims at bringing those capabilities to VW’s Python API.</p>

<h3 id="goals-1">Goals</h3>
<ul>
  <li>Understand functionality of vw-varinfo2 (Python implementation)</li>
  <li>Figure out why 2 passes are needed, figure out exact dependency on audit mode
    <ul>
      <li>Re-implement vw-varinfo2 using pyvw api, instead of using vw as a subprocess</li>
      <li>Propose and implement a proper api inside pyvw api, no more separate script</li>
    </ul>
  </li>
  <li>Deliver easy to use experience
    <ul>
      <li>Easy to use api to the end user (as in the user does not have to be guessing which args to use)</li>
      <li>Suggestion: Jupyter notebook widgets to inspect individual variables and the whole model</li>
    </ul>
  </li>
</ul>

<h3 id="stretch-goals-1">Stretch goals</h3>
<ul>
  <li>Augment Jupyter notebook experience for pyvw (easy stretch goal, could be also used as an intro to pyvw)</li>
  <li>Multiclass/CB support</li>
  <li>Figure out if some functionality can be implemented below Python api, augment cpp implementation (i.e. surface info obtained from audit mode in a more direct way rather than depending on audit mode)</li>
  <li>Weights for interaction related features</li>
</ul>

<h3 id="links">Links</h3>
<ul>
  <li><a href="https://github.com/VowpalWabbit/vowpal_wabbit/wiki/Using-vw-varinfo">https://github.com/VowpalWabbit/vowpal_wabbit/wiki/Using-vw-varinfo</a></li>
  <li><a href="https://github.com/arielf/weight-loss/blob/master/vw-varinfo2">https://github.com/arielf/weight-loss/blob/master/vw-varinfo2</a></li>
</ul>

<h2 id="3-add-extensive-benchmarks-to-vw">3. Add extensive benchmarks to VW</h2>
<p>VW has an experimental benchmarking solution but since it is a project where performance is central, having more extensive coverage is important.
The benchmarks will run on every code change and help contributors assess their immediate impact and long term trends.</p>

<h3 id="goals-2">Goals</h3>
<ul>
  <li>Implement micro and end-to-end benchmarks for VW
    <ul>
      <li>Focus on latency performance but could also consider throughput</li>
    </ul>
  </li>
  <li>Add developer tools to debug performance issues (e.g. flamegraph visualizations, git bisect scripts)</li>
  <li>Setup CI pipeline(s) to run the benchmarks</li>
</ul>

<h3 id="stretch-goals-2">Stretch goals</h3>
<ul>
  <li>Track and visualize long term performance trends</li>
  <li>Ability to compare all tests between VW versions/releases</li>
  <li>Ability to run the same VW benchmark on different libraries and compare</li>
</ul>

<h3 id="links-1">Links</h3>
<ul>
  <li><a href="https://github.com/VowpalWabbit/vowpal_wabbit/blob/master/.github/workflows/run_benchmarks.yml">Current experimental benchmark yml file</a></li>
  <li><a href="https://github.com/VowpalWabbit/vowpal_wabbit/actions?query=workflow%3A%22Run+Benchmarks%22">Current experimental benchmark pipeline</a></li>
  <li><a href="https://github.com/VowpalWabbit/vowpal_wabbit/tree/master/test/benchmarks">current experimental benchmark code</a></li>
  <li><a href="https://wiki.mozilla.org/EngineeringProductivity/Projects/Perfherder">Framework used by arewefastyer.com</a></li>
</ul>

<h2 id="4-tensorboard-and-tensorwatch-integration">4. Tensorboard and Tensorwatch Integration</h2>
<p>Integrate VW and RLClientLib(rl_sim) with Tensorboard and TensorWatch.
It would allow VW training to be overseen using TensorBoard / TensorWatch visualizations.</p>

<h3 id="goals-3">Goals</h3>
<ul>
  <li>Integrate VW training with TensorWatch within a Jupyter notebook.</li>
  <li>Extend VW to output TensorBoard logs.</li>
  <li>Extend RLClientLib(rl_sim) to support TensorBoard and TensorWatch in the same way.</li>
</ul>

<h3 id="stretch-goals-3">Stretch Goals</h3>
<ul>
  <li>Support distribution, what-if and hyperparam tunning features of TensorBoard</li>
</ul>

<h3 id="links-2">Links</h3>
<ul>
  <li><a href="https://github.com/Microsoft/tensorwatch">https://github.com/Microsoft/tensorwatch</a></li>
  <li><a href="https://www.tensorflow.org/tensorboard">https://www.tensorflow.org/tensorboard</a></li>
</ul>

<h2 id="5-vw-server-mode-revamp">5. VW Server mode revamp</h2>
<p>VW’s current model serving uses an old-school daemon that is quite limited.
We want to modernize it and convert into a service using GRPC and a richer set of features.</p>

<h3 id="goals-4">Goals</h3>
<ul>
  <li>Single model serving using GRPC with the following endpoints:
    <ul>
      <li>Predict</li>
      <li>Learn</li>
      <li>Statistics (number of features, current loss, etc)</li>
      <li>Management (download current model, number of features)</li>
    </ul>
  </li>
  <li>Wiki page describing how to use it</li>
</ul>

<h3 id="stretch-goals-4">Stretch goals</h3>
<ul>
  <li>Persistent model storage</li>
  <li>Multiple models from a single daemon</li>
  <li>Packaging tools with VW params and model</li>
</ul>

<h3 id="links-3">Links</h3>
<ul>
  <li><a href="https://grpc.io/">GRPC</a></li>
</ul>

<h2 id="6-end-to-load-local-training-loop-for-reinforcement-learning">6. End-to-load local training loop for reinforcement learning</h2>
<p>Our reinforcement-learning library currently doesn’t offer an end-to-end local experience and requires some networked services for it.
Add a mode that works entirely local would be a great tool for learning and prototyping.</p>

<h3 id="goals-5">Goals</h3>
<ul>
  <li>In-memory joining and training</li>
  <li>Extend configuration to enable local mode</li>
  <li>Python and C# API support</li>
</ul>

<h3 id="stretch-goals-5">Stretch Goals</h3>
<ul>
  <li>Checkpointing, load/save model</li>
  <li>Port some of our VW simulators to use it</li>
</ul>

<h2 id="7-contextual-bandits-estimators-in-python">7. Contextual Bandits Estimators in Python</h2>
<p>All of VW’s estimators used by contextual bandits are implemented in C++. This makes it a lot harder to work on new ones.
The goal of this project is allow them to be implemented in Python.</p>

<h3 id="goals-6">Goals</h3>
<ul>
  <li>Add hooks for Python cb_type estimator</li>
  <li>Covert current IPS estimator to Python.</li>
</ul>

<h3 id="stretch-goals-6">Stretch Goals</h3>
<ul>
  <li>Integrate this with VW’s estimators library</li>
</ul>

<h3 id="links-4">Links</h3>
<ul>
  <li><a href="https://github.com/VowpalWabbit/vowpal_wabbit/wiki/What-is-a-learner%3F">https://github.com/VowpalWabbit/vowpal_wabbit/wiki/What-is-a-learner%3F</a></li>
  <li><a href="https://github.com/VowpalWabbit/vowpal_wabbit/wiki/VW-Reductions-Workflows">https://github.com/VowpalWabbit/vowpal_wabbit/wiki/VW-Reductions-Workflows</a></li>
</ul>

<h1 id="8-extensibility-improvements-to-rlclientlib">8. Extensibility improvements to RLClientLib</h1>
<p>VW’s RL client library currently has most of its extension points available only thought the C++ API.
This limits a lot of what can be done by our users. Making those extension points available in Python and/or C# would make the library significantly more useful for our users.</p>

<h3 id="goals-7">Goals</h3>
<ul>
  <li>The i_model extension point for inference.</li>
  <li>Create an example of using it to expose a sklearn model.</li>
</ul>

<h3 id="stretch-goals-7">Stretch Goals</h3>
<ul>
  <li>The i_transport extension point for log shipping</li>
  <li>The i_model_downloader extension point for model managament</li>
</ul>

<h3 id="links-5">Links</h3>
<ul>
  <li><a href="https://github.com/vowpalwabbit/reinforcement_learning">https://github.com/vowpalwabbit/reinforcement_learning</a></li>
</ul>

<h2 id="9-sample-data-generator-library">9. Sample Data Generator Library</h2>
<p>A library of functions that can simplify generating sample data in all of VW’s input formats (text, json, fb) and problem types (regression, classification, CB, etc)</p>

<h3 id="goals-8">Goals</h3>
<ul>
  <li>A specification of the distribution of examples (e.g. number of features, feature types, feature sizes, string lengths, number of adf/ldf examples per multi_ex, action cadinality, etc)</li>
  <li>A specification of the number of examples</li>
  <li>Text / JSON / FlatBuffer support</li>
</ul>

<h3 id="stretch-goals-8">Stretch goals</h3>
<ul>
  <li>Bindability/x-lang (use from multiple languages)</li>
  <li>Multiple ways of input (command line, API, input file)</li>
</ul>

<h2 id="10-implement-and-evaluate-stream-join-algorithms">10. Implement and evaluate stream join algorithms</h2>
<p>Large scale deployments of RL require doing a distributed data join of decisions and rewards.
It’s not a simple problem as, in the real world, there could be a significant delay (days or weeks) between the decision and the reward.
This project aims to investigate and design alternatives and prototype them.</p>

<h3 id="goals-9">Goals</h3>
<ul>
  <li>Investigate system alternatives and algorithms for stream join</li>
  <li>Design and implement a stream joiner prototype</li>
  <li>Evaluate performance and compare with naïve, in-memory, solutions.</li>
</ul>

<h3 id="stretch-goals-9">Stretch goals</h3>
<ul>
  <li>Cloud prototype</li>
</ul>

<h2 id="11-rlclientlib-dataflow-benchmarks">11. RLClientLib dataflow benchmarks</h2>
<p>Key features of RLClientLib are:</p>
<ul>
  <li>Maximize throughput</li>
  <li>Minimize latency of inference calls</li>
</ul>

<p>But so far we are not measuring it in any standardized way (and it is not trivial to do since numbers depend a lot on multiple factors like number of threads, payload size, network condition etc).
We have some pieces such as (reinforcement_learning/test_tools/sender_test)[https://github.com/VowpalWabbit/reinforcement_learning/tree/master/test_tools/sender_test]
and (reinforcement_learning/examples/test_cpp)[https://github.com/VowpalWabbit/reinforcement_learning/tree/master/examples/test_cpp] which we are using from time to time for some ad-hoc testing, but arranging it into some unified benchmarking suite which we can run regularly and track progress/regression.</p>

<h3 id="goals-10">Goals</h3>
<ul>
  <li>Design latency and throughput benchmarks for client library</li>
  <li>Setup CI pipeline(s) to run the benchmarks</li>
</ul>

<h2 id="12-rlclientlib--end-to-end-learning-benchmarks">12. RLClientLib / End to end learning benchmarks</h2>
<p>There is a theoretical understanding of the learning performance of using VW directly. But in the real world, there are extra factors such as scheduled model updates that affect observed performance. We have no notion of end-to-end learning performance and no way to get any quantitative benchmarks of that kind. This project wants to identify and quantify the impact of those factors.</p>

<h3 id="goals-11">Goals</h3>
<ul>
  <li>Improve the end to end RLClientLib ecosystem so we can evaluate the impact of each of those factors</li>
</ul>

<h3 id="outcomes">Outcomes</h3>
<ul>
  <li>Changes to RLClientLib and VW to allow for closer to real world evaluation</li>
  <li>An understanding of the impact of those factors</li>
</ul>

<h3 id="risks">Risks</h3>
<p>This is an advanced project that will require the student to understand quite a bit of RL.</p>

<h3 id="links-6">Links</h3>
<ul>
  <li><a href="https://github.com/VowpalWabbit/vowpal_wabbit">VowpalWabbit</a></li>
  <li><a href="https://github.com/VowpalWabbit/reinforcement_learning">RLClientLib</a></li>
</ul>

<h2 id="13-integrate-estimator-library-into-azure-machine-learning-aml-pipeline">13. Integrate estimator library into Azure Machine Learning (AML) pipeline</h2>

<p>The current AML pipeline only produces the average loss from VW, for counterfactual evaluation, we’d like to add the data aggregation step into the pipeline.</p>

<h3 id="goals-12">Goals:</h3>
<ul>
  <li>Support counterfactual evaluation using different estimators.</li>
</ul>

<h3 id="stretch-goals-10">Stretch goals:</h3>
<ul>
  <li>Visualize the results in Python</li>
</ul>

<h3 id="outcomes-1">Outcomes:</h3>
<ul>
  <li>Package and release the estimator lib</li>
  <li>Design the counterfactual evaluation log format which supports different estimators</li>
  <li>Add aggregation step in AML pipeline</li>
</ul>

<h3 id="links-7">Links:</h3>
<ul>
  <li><a href="https://github.com/VowpalWabbit/data-science/tree/master/from_mwt_ds/DataScience/VwPipeline">https://github.com/VowpalWabbit/data-science/tree/master/from_mwt_ds/DataScience/VwPipeline</a></li>
  <li><a href="https://github.com/VowpalWabbit/estimators">https://github.com/VowpalWabbit/estimators</a></li>
</ul>

<h2 id="14-extend-fairlearn-to-include-rl-bias-analysis-using-vw">14. Extend FairLearn to include RL bias analysis using VW</h2>
<p>Most RL algorithms focus on “how can a policy maximize rewards?”. But what if higher rewards on average are obtained at the expense of rewards reduced for a sub-population? With AI and specifically VW being used extensively for personalization, good tools to identify and understand biases will have positive societal impact in use of RL.</p>

<p>This project will create an analysis script &amp; code that takes sensitive variables(features) into account in counterfactual evaluations to help discover and possibly mitigate biased rewards. The project outcomes will make it into FairLearn, a broadly used open source toolkit for Bias &amp; Fairness that is used in industry. You will interact with researchers, AI ethics experts, industry engineers and PMs to onramp on the concepts &amp; tools and get guidance when you want to.</p>

<h3 id="goals-13">Goals:</h3>
<ul>
  <li>Create code that runs counterfactual analysis of VW data logs, splitting analysis by cohorts defined by sensitive variables, and producing useful output conclusions and report. This can build starting from existing open source analysis scripts.</li>
  <li>Contribute the code and scripts and your work into FairLearn, with some basic how-to documentation for others to run it. This may include a synthetic demo dataset to showcase examples.</li>
  <li>Document what you have learned along the way about reinforcement learning and bias &amp; fairness topics, and co-author a blog post with sponsors/experts.
Mentor: Rodrigo</li>
</ul>

<h3 id="stretch-goals-11">Stretch Goals:</h3>
<ul>
  <li>Discuss &amp; document pros/cons and tradeoffs, if any, of using different reward estimators in this type of analysis</li>
  <li>Discuss concepts such as Atkinson Index and Simpsons Paradox to identify sources of inequality, including them in the analysis</li>
  <li>Invent wireframes for visualizations that make biased rewards clear to users, (and optionally code them in the tools)</li>
  <li>Come up with a conceptual definition of “robustly better policy” and “do no harm” that applies to VW/ CB policies, considering sensitive variables in the definition.</li>
</ul>

<h3 id="outcomes-2">Outcomes:</h3>
<ul>
  <li>FairLearn includes VW-based counterfactual analysis of rewards considering sensitive features,</li>
  <li>A co-authored blog post</li>
</ul>

<h3 id="links-8">Links:</h3>
<ul>
  <li><a href="https://fairlearn.github.io/">FairLearn</a></li>
</ul>

<h2 id="15-reproducible-and-programmable-feature-engineering-reduction">15. Reproducible and programmable feature engineering reduction</h2>
<p>Reliable feature engineering across training and inference is a common source of bug in real world RL systems.
By making more programable feature engineering available to VW users, we save them from having this sort of issues
plus it makes for much simpler experimentation as train files don’t need to be modified.</p>

<h3 id="goals-14">Goals:</h3>
<ul>
  <li>Enable programmatic feature engineering to be done using CEL (Google’s Common Expression Language).</li>
  <li>Those expressions can be saved in the model, making them transparently available during inference.</li>
  <li>Add a bunch of built-in functions to enable common feature engineering tasks such as interaction, binning and normalization.</li>
</ul>

<h3 id="outcomes-3">Outcomes:</h3>
<ul>
  <li>Contributions to VW that allow CEL to be used for feature engineering.</li>
</ul>

<h2 id="16-vw-parallel-parsing-improvements">16. VW Parallel parsing improvements</h2>
<p>Example parsing is an expensive part of VW training pipeline. Support for parallel parsing of text input was contributed last year, but it doesn’t support the more efficient cache format.</p>

<h3 id="goals-15">Goals</h3>
<ul>
  <li>Design and implement an extension to the cache file format to support efficient parallel parsing</li>
</ul>

<h3 id="outcomes-4">Outcomes</h3>
<ul>
  <li>Ability to utilize mutlicore machines more effectively when training with cache format</li>
</ul>

<h2 id="17-rl-based-query-planner-for-open-source-sql-engine">17. RL-based query planner for open-source SQL engine</h2>
<p>Query planning with Reinforcement Learning in an active area of research and we want to enable VW to be used for it by embedding VW into a popular open source SQL engine.</p>

<h3 id="goals-16">Goals</h3>
<ul>
  <li>Modify an open source engine (SQLite, MySQL or PostgreSQL) to use RLClientLib for some of the query query planning decisions.</li>
  <li>Enable offline experimentation by producing a large body of exploratory data against well-established benchmarks.</li>
</ul>

<h3 id="outcomes-5">Outcomes</h3>
<p>A modified SQL engine that would enable further research on RL and Query Planning.</p>

<h2 id="18--vw-port-to-webassembly-and-javascript-api">18.  VW port to WebAssembly and JavaScript API</h2>
<p>Javascript is the most popular programing language in the world and yet it’s not possible to use VW from it. WebAssembly allows running C/C++ code in the browser and is the right vehicle to bring VW there.</p>

<h3 id="goals-17">Goals</h3>
<p>The MSR team started a WebAssembly port of VW but never went beyond a prototype.</p>
<ul>
  <li>Wrap up and merge those changes.</li>
  <li>Design and implement a JavaScript-centric API</li>
</ul>

<h3 id="stretch-goals-12">Stretch Goals:</h3>
<ul>
  <li>NPM package</li>
  <li>Ensure it works on non-browser environments such as node and vscode</li>
</ul>

<h3 id="outcome">Outcome:</h3>
<ul>
  <li>First class support for VW from JavaScript</li>
</ul>

<h2 id="19-support-creating-a-reduction-in-rust">19. Support creating a reduction in Rust</h2>
<p>A recent area of exploration we have been working on in supporting reductions implemented in languages other than C++. Rust would integrate well with C++ and VW and as such we would like it to become well supported in the ecosystem. Initial work for Rust+VW has been started here, but more work in needed on the C API and the Rust bindings consuming it.</p>

<h3 id="goals-18">Goals</h3>
<ul>
  <li>Flesh out required functions in the new C API to facilitate required functionality</li>
  <li>Simple reduction implemented in Rust</li>
</ul>

<h3 id="stretch-goals-13">Stretch Goals</h3>
<ul>
  <li>NPM package.</li>
  <li>Support dynamic loading of the reduction</li>
</ul>

<h3 id="outcome-1">Outcome</h3>
<ul>
  <li>Ability to define and run a reduction implemented in Rust</li>
</ul>

<h3 id="links-9">Links</h3>
<ul>
  <li><a href="https://github.com/jackgerrits/vowpalwabbit-sys-rs">https://github.com/jackgerrits/vowpalwabbit-sys-rs</a></li>
  <li><a href="https://github.com/jackgerrits/vowpalwabbit-rs">https://github.com/jackgerrits/vowpalwabbit-rs</a></li>
</ul>

<h2 id="20-automl-for-online-learning">20. AutoML for online learning</h2>
<p>Hyperparameter tuning is widely used in machine learning when trying to find the optimal learning algorithm. This is usually achieved via hyperparameter sweeping and is often performed manually, while requires enough knowledge and understanding of the data and the learning algorithm at hand.</p>

<p>This project will focus on implementing AutoML techniques for online training in VW, focusing on the area of hyperparameter tuning.</p>

<h3 id="goals-19">Goals</h3>
<ul>
  <li>Implement AutoML techniques</li>
  <li>Provide visualizations (or other appropriate output) that demonstrates the parameter tuning and how the model learns to perform better/worse as the parameters are tuned</li>
</ul>

<h3 id="outcomes-6">Outcomes</h3>
<ul>
  <li>PR against the vowpalwabbit repo</li>
  <li>wiki-page describing how to achieve auto parameter tuning</li>
</ul>

<h3 id="links-10">Links</h3>
<ul>
  <li><a href="https://www.automl.org/">https://www.automl.org/</a></li>
</ul>

<h2 id="21-federated-residual-learning-prototype">21. Federated Residual Learning Prototype</h2>
<p>Traditional Machine Learning requires clients to share data with a central service, which learns joint models across all clients. This results in the need for large joint models to faithfully capture all clients’ data, with large memory and inference time needs, as well as is undesirable from a privacy perspective. Simply learning local models on the clients, which preserves privacy, is also typically undesirable as each client sees only a small volume of data. The paper https://arxiv.org/abs/2003.12880 outlines a Federated Learning approach which blends local personalized models with global joint models, and achieves higher performance than purely joint or local learning approaches. This project aims to implement the algorithms laid out in the paper using VW and evaluating them at scale.</p>

<h3 id="goals-20">Goals</h3>
<ul>
  <li>Client and server implementations of FedRes, as well as other popular Federated Learning algorithms.</li>
  <li>Study its performance using a diverse collection of datasets.</li>
</ul>

<h2 id="22-safe-contextual-bandits">22. Safe Contextual Bandits</h2>
<p>Contextual Bandit algorithms are commonly designed to maximize the expected reward over time which is the right choice in scenarios where the only cost of choosing the worst arm is increased regret. In systems settings where there’s an SLA or safety constraint, avoiding bad actions is as important as learning the optimal one.
 
The goal of this project is to address those scenarios by developing a CB algorithm that takes a constraint signal together with the reward signal and trains a policy that maximizes reward subject to the probability of violating the constraint signal.</p>

          </div>
        </div>
      </div>
      <script src="/assets/js/tutorial.js"></script>
    </div>
    
    <div class="container-fluid footer_container">
  <div class="container">
    <div class="row align-items-center justify-content-between">
      <div class="col">
        Microsoft is a major contributor
      </div>
      <div class="col feedback_col">
        <a
          class="feedback_link"
          href="https://github.com/VowpalWabbit/vowpalwabbit.github.io/issues/new"
          target="_blank"
        >
          Feedback
        </a>
      </div>
    </div>
  </div>
</div>

<script src="/assets/js/citation.js"></script>

    <div class="overlay">
    </div>
  </body>
</html>
