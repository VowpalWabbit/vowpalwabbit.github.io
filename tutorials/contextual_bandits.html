<!doctype html>
<html lang="en">
  <head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="shortcut icon" type="image/x-icon" href="/assets/images/favicon.png">
  <link rel="canonical" href="/tutorials/contextual_bandits.html" />
  <link rel="stylesheet" href="/assets/bootstrap-4.1.3-dist/css/bootstrap.min.css">
  <link rel="stylesheet" href="/assets/syntax.css">
  <link rel="stylesheet" href="/assets/main.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
  <link href="https://fonts.googleapis.com/css?family=Work+Sans:300,400,600&display=swap" rel="stylesheet">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.4.0/jquery.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.11.0/umd/popper.min.js" integrity="sha384-b/U6ypiBEHpOf/4+1nzFpr53nxSS+GLCkfwBdFNTxtclqqenISfwAzpKaMNFNmj4" crossorigin="anonymous"></script>
  <script src="/assets/app.js"></script>

  <title>Contextual Bandits Reinforcement Learning | Vowpal Wabbit</title>
  <meta name="description" content="This tutorial includes an overview of the contextual bandits approach to reinforcement learning and how to approach this problem using Vowpal Wabbit." >
</head>


  <body class="tutorial">
    


<div class="navbar_container  main_nav_container">
  <div class="container navbar">
    <div class="logo">
      <a href="/index.html">
        <?xml version="1.0" encoding="UTF-8"?>
<svg width="172px" height="30px" viewBox="0 0 172 30" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
    <!-- Generator: Sketch 57.1 (83088) - https://sketch.com -->
    <title>logo_vw_horiz_gray</title>
    <desc>Created with Sketch.</desc>
    <g id="Styles" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
        <g id="Desktop-Copy" transform="translate(-944.000000, -314.000000)">
            <g id="logo_vw_horiz_gray" transform="translate(941.000000, 314.000000)">
                <rect id="framework" x="0" y="0" width="175" height="30"></rect>
                <path d="M49.488,22 L46.59,22 L42.252,10.12 L44.88,10.12 L47.382,17.68 L48.066,20.02 L48.732,17.698 L51.252,10.12 L53.808,10.12 L49.488,22 Z M58.524,12.82 C59.9760073,12.82 61.106996,13.2339959 61.917,14.062 C62.7270041,14.8900041 63.132,16.0359927 63.132,17.5 C63.132,18.9640073 62.7270041,20.1099959 61.917,20.938 C61.106996,21.7660041 59.9760073,22.18 58.524,22.18 C57.0719927,22.18 55.9410041,21.7660041 55.131,20.938 C54.320996,20.1099959 53.916,18.9640073 53.916,17.5 C53.916,16.0359927 54.320996,14.8900041 55.131,14.062 C55.9410041,13.2339959 57.0719927,12.82 58.524,12.82 Z M58.524,14.656 C57.8279965,14.656 57.2970018,14.8929976 56.931,15.367 C56.5649982,15.8410024 56.382,16.5519953 56.382,17.5 C56.382,18.4480047 56.5649982,19.1589976 56.931,19.633 C57.2970018,20.1070024 57.8279965,20.344 58.524,20.344 C59.2200035,20.344 59.7509982,20.1070024 60.117,19.633 C60.4830018,19.1589976 60.666,18.4480047 60.666,17.5 C60.666,16.5519953 60.4830018,15.8410024 60.117,15.367 C59.7509982,14.8929976 59.2200035,14.656 58.524,14.656 Z M79.368,13 L76.506,22 L73.644,22 L71.682,15.646 L69.792,22 L66.948,22 L64.086,13 L66.696,13 L68.496,20.02 L70.512,13 L72.942,13 L74.958,20.02 L76.758,13 L79.368,13 Z M86.316,12.82 C87.516006,12.82 88.4579966,13.2309959 89.142,14.053 C89.8260034,14.8750041 90.168,16.0179927 90.168,17.482 C90.168,18.9580074 89.8260034,20.1099959 89.142,20.938 C88.4579966,21.7660041 87.516006,22.18 86.316,22.18 C85.6679968,22.18 85.1040024,22.0330015 84.624,21.739 C84.1439976,21.4449985 83.7660014,21.0400026 83.49,20.524 L83.49,25.78 L81.024,25.78 L81.024,13 L83.202,13 L83.292,14.782 C83.5560013,14.181997 83.9489974,13.7050018 84.471,13.351 C84.9930026,12.9969982 85.6079965,12.82 86.316,12.82 Z M85.578,20.29 C86.2500034,20.29 86.7719981,20.0500024 87.144,19.57 C87.5160019,19.0899976 87.702,18.4000045 87.702,17.5 C87.702,16.5999955 87.5160019,15.9100024 87.144,15.43 C86.7719981,14.9499976 86.2500034,14.71 85.578,14.71 C84.977997,14.71 84.4920019,14.9169979 84.12,15.331 C83.7479981,15.7450021 83.5380002,16.3359962 83.49,17.104 L83.49,17.896 C83.5380002,18.6520038 83.7479981,19.2399979 84.12,19.66 C84.4920019,20.0800021 84.977997,20.29 85.578,20.29 Z M100.518,20.506 C100.770001,20.506 100.973999,20.4820002 101.13,20.434 L100.95,21.928 C100.613998,22.0960008 100.224002,22.18 99.78,22.18 C98.6279942,22.18 97.9380011,21.7300045 97.71,20.83 C97.4459987,21.2740022 97.0380028,21.6099989 96.486,21.838 C95.9339972,22.0660011 95.2800038,22.18 94.524,22.18 C93.6479956,22.18 92.9640025,21.982002 92.472,21.586 C91.9799975,21.189998 91.734,20.6200037 91.734,19.876 C91.734,18.4119927 92.9039883,17.4640022 95.244,17.032 L97.404,16.618 L97.404,16.186 C97.404,15.7059976 97.2690014,15.3250014 96.999,15.043 C96.7289987,14.7609986 96.3540024,14.62 95.874,14.62 C95.3219972,14.62 94.8720017,14.7399988 94.524,14.98 C94.1759983,15.2200012 93.9360007,15.6099973 93.804,16.15 L91.842,15.322 C92.034001,14.5419961 92.4659966,13.9300022 93.138,13.486 C93.8100034,13.0419978 94.6859946,12.82 95.766,12.82 C97.0500064,12.82 98.0519964,13.0989972 98.772,13.657 C99.4920036,14.2150028 99.852,15.0399945 99.852,16.132 L99.852,19.822 C99.852,20.0620012 99.9059995,20.2359995 100.014,20.344 C100.122001,20.4520005 100.289999,20.506 100.518,20.506 Z M95.298,20.506 C95.8260026,20.506 96.3089978,20.3770013 96.747,20.119 C97.1850022,19.8609987 97.404,19.5100022 97.404,19.066 L97.404,18.13 L95.478,18.562 C95.069998,18.6580005 94.767001,18.7869992 94.569,18.949 C94.370999,19.1110008 94.272,19.3359986 94.272,19.624 C94.272,19.9120014 94.3619991,20.1309992 94.542,20.281 C94.7220009,20.4310007 94.9739984,20.506 95.298,20.506 Z M105.054,19.138 C105.054,19.5700022 105.116999,19.8699992 105.243,20.038 C105.369001,20.2060008 105.599998,20.29 105.936,20.29 C106.140001,20.29 106.316999,20.2750001 106.467,20.245 C106.617001,20.2149998 106.793999,20.1640004 106.998,20.092 L106.782,21.802 C106.589999,21.9220006 106.338002,22.0149997 106.026,22.081 C105.713998,22.1470003 105.408002,22.18 105.108,22.18 C104.231996,22.18 103.593002,21.9670021 103.191,21.541 C102.788998,21.1149979 102.588,20.4340047 102.588,19.498 L102.588,9.058 L105.054,9.058 L105.054,19.138 Z M118.482,22 L115.62,22 L112.164,10.12 L114.846,10.12 L117.15,20.038 L119.526,10.12 L121.902,10.12 L124.314,20.038 L126.618,10.12 L129.174,10.12 L125.718,22 L122.928,22 L121.272,15.52 L120.714,12.712 L120.678,12.712 L120.12,15.52 L118.482,22 Z M138.336,20.506 C138.588001,20.506 138.791999,20.4820002 138.948,20.434 L138.768,21.928 C138.431998,22.0960008 138.042002,22.18 137.598,22.18 C136.445994,22.18 135.756001,21.7300045 135.528,20.83 C135.263999,21.2740022 134.856003,21.6099989 134.304,21.838 C133.751997,22.0660011 133.098004,22.18 132.342,22.18 C131.465996,22.18 130.782002,21.982002 130.29,21.586 C129.797998,21.189998 129.552,20.6200037 129.552,19.876 C129.552,18.4119927 130.721988,17.4640022 133.062,17.032 L135.222,16.618 L135.222,16.186 C135.222,15.7059976 135.087001,15.3250014 134.817,15.043 C134.546999,14.7609986 134.172002,14.62 133.692,14.62 C133.139997,14.62 132.690002,14.7399988 132.342,14.98 C131.993998,15.2200012 131.754001,15.6099973 131.622,16.15 L129.66,15.322 C129.852001,14.5419961 130.283997,13.9300022 130.956,13.486 C131.628003,13.0419978 132.503995,12.82 133.584,12.82 C134.868006,12.82 135.869996,13.0989972 136.59,13.657 C137.310004,14.2150028 137.67,15.0399945 137.67,16.132 L137.67,19.822 C137.67,20.0620012 137.723999,20.2359995 137.832,20.344 C137.940001,20.4520005 138.107999,20.506 138.336,20.506 Z M133.116,20.506 C133.644003,20.506 134.126998,20.3770013 134.565,20.119 C135.003002,19.8609987 135.222,19.5100022 135.222,19.066 L135.222,18.13 L133.296,18.562 C132.887998,18.6580005 132.585001,18.7869992 132.387,18.949 C132.188999,19.1110008 132.09,19.3359986 132.09,19.624 C132.09,19.9120014 132.179999,20.1309992 132.36,20.281 C132.540001,20.4310007 132.791998,20.506 133.116,20.506 Z M145.734,12.82 C146.934006,12.82 147.875997,13.2339959 148.56,14.062 C149.244003,14.8900041 149.586,16.0419926 149.586,17.518 C149.586,18.9820073 149.244003,20.1249959 148.56,20.947 C147.875997,21.7690041 146.934006,22.18 145.734,22.18 C145.025996,22.18 144.411003,22.0030018 143.889,21.649 C143.366997,21.2949982 142.974001,20.818003 142.71,20.218 L142.62,22 L140.442,22 L140.442,9.058 L142.908,9.058 L142.908,14.476 C143.184001,13.9599974 143.561998,13.5550015 144.042,13.261 C144.522002,12.9669985 145.085997,12.82 145.734,12.82 Z M144.996,20.29 C145.668003,20.29 146.189998,20.0500024 146.562,19.57 C146.934002,19.0899976 147.12,18.4000045 147.12,17.5 C147.12,16.5999955 146.934002,15.9100024 146.562,15.43 C146.189998,14.9499976 145.668003,14.71 144.996,14.71 C144.395997,14.71 143.910002,14.9199979 143.538,15.34 C143.165998,15.7600021 142.956,16.3479962 142.908,17.104 L142.908,17.896 C142.956,18.6640038 143.165998,19.2549979 143.538,19.669 C143.910002,20.0830021 144.395997,20.29 144.996,20.29 Z M157.056,12.82 C158.256006,12.82 159.197997,13.2339959 159.882,14.062 C160.566003,14.8900041 160.908,16.0419926 160.908,17.518 C160.908,18.9820073 160.566003,20.1249959 159.882,20.947 C159.197997,21.7690041 158.256006,22.18 157.056,22.18 C156.347996,22.18 155.733003,22.0030018 155.211,21.649 C154.688997,21.2949982 154.296001,20.818003 154.032,20.218 L153.942,22 L151.764,22 L151.764,9.058 L154.23,9.058 L154.23,14.476 C154.506001,13.9599974 154.883998,13.5550015 155.364,13.261 C155.844002,12.9669985 156.407997,12.82 157.056,12.82 Z M156.318,20.29 C156.990003,20.29 157.511998,20.0500024 157.884,19.57 C158.256002,19.0899976 158.442,18.4000045 158.442,17.5 C158.442,16.5999955 158.256002,15.9100024 157.884,15.43 C157.511998,14.9499976 156.990003,14.71 156.318,14.71 C155.717997,14.71 155.232002,14.9199979 154.86,15.34 C154.487998,15.7600021 154.278,16.3479962 154.23,17.104 L154.23,17.896 C154.278,18.6640038 154.487998,19.2549979 154.86,19.669 C155.232002,20.0830021 155.717997,20.29 156.318,20.29 Z M164.328,11.704 C163.307995,11.704 162.798,11.2660044 162.798,10.39 C162.798,9.50199556 163.307995,9.058 164.328,9.058 C165.348005,9.058 165.858,9.50199556 165.858,10.39 C165.858,11.2660044 165.348005,11.704 164.328,11.704 Z M165.552,22 L163.086,22 L163.086,13 L165.552,13 L165.552,22 Z M174.336,21.442 C174.047999,21.6700011 173.685002,21.8499993 173.247,21.982 C172.808998,22.1140007 172.350002,22.18 171.87,22.18 C169.86599,22.18 168.864,21.2740091 168.864,19.462 L168.864,14.836 L167.226,14.836 L167.226,13 L168.864,13 L168.864,10.93 L171.33,10.246 L171.33,13 L174.246,13 L174.246,14.836 L171.33,14.836 L171.33,19.066 C171.33,19.8940041 171.743996,20.308 172.572,20.308 C173.100003,20.308 173.561998,20.1400017 173.958,19.804 L174.336,21.442 Z" id="VowpalWabbit" fill="#333333" fill-rule="nonzero"></path>
                <g id="logo_vw_color" transform="translate(3.000000, 0.000000)" fill="#2A3B93">
                    <path d="M27.9875518,16.6117194 C27.9875518,9.21947752 21.9666728,9.36035971 21.9666728,9.36035971 C21.3736977,6.15536974 20.3362508,3.5963294 19.3414955,1.96947553 C18.1790857,0.436543115 17.3241355,0 17.3241355,0 C16.2887633,0.700737156 15.7766231,3.93943024 15.7766231,3.93943024 C14.1726939,1.18184505 12.329851,1.05294263 12.329851,1.05294263 C9.93824094,8.37466357 17.0427696,11.1203489 17.0427696,11.1203489 C9.97542657,11.1203489 6.33307087,15.0400524 4.59284756,17.9877167 C4.0042614,19.0524794 3.60319929,20.0302689 3.35048069,20.7371557 L2.99801525,21.8605394 C1.89952322,21.2108361 0.011355398,21.1878349 0.011355398,21.1878349 C-0.278708419,29.2136474 5.0845596,28.0167877 5.0845596,28.0167877 C5.0845596,29.1432063 6.56177043,30 6.56177043,30 L18.0978518,30 C18.0978518,30 17.9248509,28.5478912 16.7183131,27.7616983 C16.5196972,27.4693917 16.4533057,27.212705 16.6897456,26.9422016 C17.354698,26.1816454 17.8296525,27.1798804 17.8296525,27.1798804 L18.3302221,27.8553801 C19.7539686,29.627988 20.7440159,29.9516816 21.1646284,30 L21.391732,30 C20.5763614,27.5009384 20.6054875,25.3190215 20.6054875,25.3190215 C20.4822802,22.1365535 22.8107704,19.2166024 22.8107704,19.2166024 C28.5084697,19.2166024 27.9875518,16.6117194 27.9875518,16.6117194" id="logo_rabbit"></path>
                </g>
            </g>
        </g>
    </g>
</svg>
      </a>
    </div>

    <div class="nav">
      <a
        href="/start.html"
        class=''
      >
        Get started
      </a>
      <a
        href="/features.html"
        class=''
      >
        Features
      </a>
      <a
        href="/tutorials.html"
        class='active'
      >
        Tutorials
      </a>
      <a
        href="/blog.html"
        class=''
      >
        Blog
      </a>
      <a
        href="/research.html"
        class=''
      >
        Research
      </a>
      <div class="external_links">
        <a
          href="https://github.com/VowpalWabbit/vowpal_wabbit/wiki"
          target="_blank"
        >
          Wiki
        </a>

        <a
          href="https://github.com/VowpalWabbit/vowpal_wabbit"
          target="_blank"
          class="github_link"
        >
          <?xml version="1.0" encoding="UTF-8"?>
<svg width="30px" height="30px" viewBox="0 0 30 30" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
    <!-- Generator: Sketch 53 (72520) - https://sketchapp.com -->
    <title>GitHub</title>
    <desc>Created with Sketch.</desc>
    <g id="Symbols" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
        <g id="HD_Desktop_header_Home" transform="translate(-1538.000000, -58.000000)" fill="#FFFFFF">
            <g id="Header">
                <path d="M1568,73.7951128 C1567.94603,74.2583723 1567.89891,74.7224863 1567.83682,75.1847206 C1567.56271,77.2238487 1566.86543,79.1138828 1565.7732,80.8526868 C1564.55268,82.7956941 1562.9969,84.4188114 1561.05088,85.6538569 C1560.03339,86.2996179 1558.94817,86.8066231 1557.80753,87.1895684 C1557.17559,87.4016322 1556.73848,87.0743943 1556.73531,86.4093237 C1556.72907,85.1020808 1556.73745,83.7947524 1556.73164,82.487424 C1556.72804,81.6908602 1556.64825,80.9063436 1556.21259,80.2087201 C1556.0855,80.0052003 1555.92463,79.8226135 1555.77393,79.6234512 C1556.35935,79.5140871 1556.9463,79.4362506 1557.51632,79.2916849 C1559.04696,78.9034423 1560.41543,78.2275208 1561.34791,76.8924242 C1562.03287,75.9115647 1562.34632,74.7851144 1562.48436,73.6108172 C1562.59169,72.6982249 1562.62222,71.7826422 1562.42971,70.8740656 C1562.23608,69.9599354 1561.84044,69.1418405 1561.22834,68.4359293 C1561.07756,68.2620575 1561.04763,68.1215929 1561.12221,67.896713 C1561.52468,66.6818314 1561.3562,65.491984 1560.9042,64.3262309 C1560.87829,64.2595017 1560.76574,64.1973008 1560.68569,64.1853391 C1560.15364,64.1058793 1559.65196,64.2559986 1559.18533,64.4761793 C1558.42904,64.8332361 1557.69764,65.242668 1556.9487,65.6159585 C1556.82229,65.6790137 1556.64782,65.7219904 1556.51706,65.6889249 C1554.16941,65.0964789 1551.82595,65.097077 1549.47805,65.6883268 C1549.34078,65.7228448 1549.14638,65.677134 1549.02331,65.5987849 C1548.07109,64.9919849 1547.06446,64.5120644 1545.97001,64.2236166 C1545.9511,64.218661 1545.93272,64.2115694 1545.91364,64.2077246 C1545.22551,64.0670892 1545.09971,64.1456947 1544.9036,64.8108506 C1544.58682,65.884755 1544.5296,66.9550708 1544.90668,68.0296587 C1544.93627,68.1139033 1544.90129,68.2616303 1544.8404,68.3306664 C1543.60397,69.7341156 1543.31096,71.3989279 1543.46559,73.1936101 C1543.55933,74.2817831 1543.81162,75.3262104 1544.29869,76.3083514 C1544.97176,77.6654063 1546.11181,78.4952066 1547.4926,78.982475 C1548.35956,79.2884382 1549.27852,79.4473579 1550.18824,79.6758264 C1550.19526,79.6319098 1550.20056,79.6666842 1550.18568,79.6820635 C1549.71726,80.1697591 1549.45556,80.755028 1549.34531,81.4170227 C1549.33137,81.5007546 1549.27365,81.6203716 1549.20685,81.6454912 C1548.16482,82.0372369 1547.11706,82.2433199 1546.08683,81.6149888 C1545.61867,81.3295314 1545.27683,80.9169382 1545.00101,80.4479541 C1544.56852,79.712395 1543.95864,79.179074 1543.13923,78.9361661 C1542.84434,78.8487602 1542.50823,78.8709748 1542.19359,78.8892591 C1541.97909,78.9018189 1541.90862,79.062362 1542.05256,79.2422147 C1542.18529,79.4077988 1542.32025,79.5950849 1542.4978,79.6971865 C1543.28625,80.1507913 1543.72798,80.8753286 1544.08881,81.6641173 C1544.30382,82.1341266 1544.48812,82.6140471 1544.88675,82.9753759 C1545.52169,83.5510755 1546.29115,83.7682658 1547.11612,83.8044072 C1547.81434,83.834995 1548.51496,83.8107298 1549.24722,83.8107298 C1549.24611,83.8009041 1549.26073,83.8742123 1549.26167,83.9476058 C1549.27211,84.7377616 1549.2828,85.5279173 1549.28844,86.3180731 C1549.294,87.0913115 1548.82935,87.4109452 1548.0952,87.1563319 C1544.28705,85.8355039 1541.4928,83.3342269 1539.62819,79.7992882 C1538.22405,77.1372118 1537.78027,74.2780237 1538.09739,71.2935795 C1538.4294,68.1688416 1539.66702,65.4337134 1541.73193,63.0872551 C1543.89022,60.6347648 1546.57714,59.0045559 1549.78825,58.3523869 C1554.45335,57.4048494 1558.71409,58.3562318 1562.44442,61.3515269 C1565.27245,63.6222848 1567.02271,66.5767393 1567.72914,70.1361141 C1567.83314,70.6605492 1567.87265,71.197715 1567.94398,71.7286436 C1567.95792,71.832625 1567.9811,71.9354102 1568,72.0387934 L1568,73.7951128 Z" id="GitHub"></path>
            </g>
        </g>
    </g>
</svg>
          <div>
            GitHub
          </div>
        </a>
      </div>
    </div>
  </div>
</div>




<div class="navbar_container  mobile_nav_container">
  <div class="container navbar">
    <div class="hamburger_icon">
      <?xml version="1.0" encoding="UTF-8"?>
<svg width="18px" height="16px" viewBox="0 0 18 16" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
    <!-- Generator: sketchtool 57.1 (101010) - https://sketch.com -->
    <title>8049A6A1-2687-43E9-9B5D-E205E8F9E871</title>
    <desc>Created with sketchtool.</desc>
    <g id="Pages" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd" stroke-linecap="round">
        <g id="Mobile_home" transform="translate(-12.000000, -56.000000)" stroke="#FFFFFF" stroke-width="2">
            <g id="header">
                <g id="ui_header_mobile_dk" transform="translate(12.000000, 44.000000)">
                    <g id="icon_menu" transform="translate(1.000000, 12.500000)">
                        <g id="Line">
                            <path d="M16,0.5 L0,0.5"></path>
                            <path d="M16,7.5 L0,7.5"></path>
                            <path d="M16,14.5 L0,14.5"></path>
                        </g>
                    </g>
                </g>
            </g>
        </g>
    </g>
</svg>
    </div>
    <div class="logo">
      <a href="/index.html">
        <?xml version="1.0" encoding="UTF-8"?>
<svg width="172px" height="30px" viewBox="0 0 172 30" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
    <!-- Generator: Sketch 57.1 (83088) - https://sketch.com -->
    <title>logo_vw_horiz_gray</title>
    <desc>Created with Sketch.</desc>
    <g id="Styles" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
        <g id="Desktop-Copy" transform="translate(-944.000000, -314.000000)">
            <g id="logo_vw_horiz_gray" transform="translate(941.000000, 314.000000)">
                <rect id="framework" x="0" y="0" width="175" height="30"></rect>
                <path d="M49.488,22 L46.59,22 L42.252,10.12 L44.88,10.12 L47.382,17.68 L48.066,20.02 L48.732,17.698 L51.252,10.12 L53.808,10.12 L49.488,22 Z M58.524,12.82 C59.9760073,12.82 61.106996,13.2339959 61.917,14.062 C62.7270041,14.8900041 63.132,16.0359927 63.132,17.5 C63.132,18.9640073 62.7270041,20.1099959 61.917,20.938 C61.106996,21.7660041 59.9760073,22.18 58.524,22.18 C57.0719927,22.18 55.9410041,21.7660041 55.131,20.938 C54.320996,20.1099959 53.916,18.9640073 53.916,17.5 C53.916,16.0359927 54.320996,14.8900041 55.131,14.062 C55.9410041,13.2339959 57.0719927,12.82 58.524,12.82 Z M58.524,14.656 C57.8279965,14.656 57.2970018,14.8929976 56.931,15.367 C56.5649982,15.8410024 56.382,16.5519953 56.382,17.5 C56.382,18.4480047 56.5649982,19.1589976 56.931,19.633 C57.2970018,20.1070024 57.8279965,20.344 58.524,20.344 C59.2200035,20.344 59.7509982,20.1070024 60.117,19.633 C60.4830018,19.1589976 60.666,18.4480047 60.666,17.5 C60.666,16.5519953 60.4830018,15.8410024 60.117,15.367 C59.7509982,14.8929976 59.2200035,14.656 58.524,14.656 Z M79.368,13 L76.506,22 L73.644,22 L71.682,15.646 L69.792,22 L66.948,22 L64.086,13 L66.696,13 L68.496,20.02 L70.512,13 L72.942,13 L74.958,20.02 L76.758,13 L79.368,13 Z M86.316,12.82 C87.516006,12.82 88.4579966,13.2309959 89.142,14.053 C89.8260034,14.8750041 90.168,16.0179927 90.168,17.482 C90.168,18.9580074 89.8260034,20.1099959 89.142,20.938 C88.4579966,21.7660041 87.516006,22.18 86.316,22.18 C85.6679968,22.18 85.1040024,22.0330015 84.624,21.739 C84.1439976,21.4449985 83.7660014,21.0400026 83.49,20.524 L83.49,25.78 L81.024,25.78 L81.024,13 L83.202,13 L83.292,14.782 C83.5560013,14.181997 83.9489974,13.7050018 84.471,13.351 C84.9930026,12.9969982 85.6079965,12.82 86.316,12.82 Z M85.578,20.29 C86.2500034,20.29 86.7719981,20.0500024 87.144,19.57 C87.5160019,19.0899976 87.702,18.4000045 87.702,17.5 C87.702,16.5999955 87.5160019,15.9100024 87.144,15.43 C86.7719981,14.9499976 86.2500034,14.71 85.578,14.71 C84.977997,14.71 84.4920019,14.9169979 84.12,15.331 C83.7479981,15.7450021 83.5380002,16.3359962 83.49,17.104 L83.49,17.896 C83.5380002,18.6520038 83.7479981,19.2399979 84.12,19.66 C84.4920019,20.0800021 84.977997,20.29 85.578,20.29 Z M100.518,20.506 C100.770001,20.506 100.973999,20.4820002 101.13,20.434 L100.95,21.928 C100.613998,22.0960008 100.224002,22.18 99.78,22.18 C98.6279942,22.18 97.9380011,21.7300045 97.71,20.83 C97.4459987,21.2740022 97.0380028,21.6099989 96.486,21.838 C95.9339972,22.0660011 95.2800038,22.18 94.524,22.18 C93.6479956,22.18 92.9640025,21.982002 92.472,21.586 C91.9799975,21.189998 91.734,20.6200037 91.734,19.876 C91.734,18.4119927 92.9039883,17.4640022 95.244,17.032 L97.404,16.618 L97.404,16.186 C97.404,15.7059976 97.2690014,15.3250014 96.999,15.043 C96.7289987,14.7609986 96.3540024,14.62 95.874,14.62 C95.3219972,14.62 94.8720017,14.7399988 94.524,14.98 C94.1759983,15.2200012 93.9360007,15.6099973 93.804,16.15 L91.842,15.322 C92.034001,14.5419961 92.4659966,13.9300022 93.138,13.486 C93.8100034,13.0419978 94.6859946,12.82 95.766,12.82 C97.0500064,12.82 98.0519964,13.0989972 98.772,13.657 C99.4920036,14.2150028 99.852,15.0399945 99.852,16.132 L99.852,19.822 C99.852,20.0620012 99.9059995,20.2359995 100.014,20.344 C100.122001,20.4520005 100.289999,20.506 100.518,20.506 Z M95.298,20.506 C95.8260026,20.506 96.3089978,20.3770013 96.747,20.119 C97.1850022,19.8609987 97.404,19.5100022 97.404,19.066 L97.404,18.13 L95.478,18.562 C95.069998,18.6580005 94.767001,18.7869992 94.569,18.949 C94.370999,19.1110008 94.272,19.3359986 94.272,19.624 C94.272,19.9120014 94.3619991,20.1309992 94.542,20.281 C94.7220009,20.4310007 94.9739984,20.506 95.298,20.506 Z M105.054,19.138 C105.054,19.5700022 105.116999,19.8699992 105.243,20.038 C105.369001,20.2060008 105.599998,20.29 105.936,20.29 C106.140001,20.29 106.316999,20.2750001 106.467,20.245 C106.617001,20.2149998 106.793999,20.1640004 106.998,20.092 L106.782,21.802 C106.589999,21.9220006 106.338002,22.0149997 106.026,22.081 C105.713998,22.1470003 105.408002,22.18 105.108,22.18 C104.231996,22.18 103.593002,21.9670021 103.191,21.541 C102.788998,21.1149979 102.588,20.4340047 102.588,19.498 L102.588,9.058 L105.054,9.058 L105.054,19.138 Z M118.482,22 L115.62,22 L112.164,10.12 L114.846,10.12 L117.15,20.038 L119.526,10.12 L121.902,10.12 L124.314,20.038 L126.618,10.12 L129.174,10.12 L125.718,22 L122.928,22 L121.272,15.52 L120.714,12.712 L120.678,12.712 L120.12,15.52 L118.482,22 Z M138.336,20.506 C138.588001,20.506 138.791999,20.4820002 138.948,20.434 L138.768,21.928 C138.431998,22.0960008 138.042002,22.18 137.598,22.18 C136.445994,22.18 135.756001,21.7300045 135.528,20.83 C135.263999,21.2740022 134.856003,21.6099989 134.304,21.838 C133.751997,22.0660011 133.098004,22.18 132.342,22.18 C131.465996,22.18 130.782002,21.982002 130.29,21.586 C129.797998,21.189998 129.552,20.6200037 129.552,19.876 C129.552,18.4119927 130.721988,17.4640022 133.062,17.032 L135.222,16.618 L135.222,16.186 C135.222,15.7059976 135.087001,15.3250014 134.817,15.043 C134.546999,14.7609986 134.172002,14.62 133.692,14.62 C133.139997,14.62 132.690002,14.7399988 132.342,14.98 C131.993998,15.2200012 131.754001,15.6099973 131.622,16.15 L129.66,15.322 C129.852001,14.5419961 130.283997,13.9300022 130.956,13.486 C131.628003,13.0419978 132.503995,12.82 133.584,12.82 C134.868006,12.82 135.869996,13.0989972 136.59,13.657 C137.310004,14.2150028 137.67,15.0399945 137.67,16.132 L137.67,19.822 C137.67,20.0620012 137.723999,20.2359995 137.832,20.344 C137.940001,20.4520005 138.107999,20.506 138.336,20.506 Z M133.116,20.506 C133.644003,20.506 134.126998,20.3770013 134.565,20.119 C135.003002,19.8609987 135.222,19.5100022 135.222,19.066 L135.222,18.13 L133.296,18.562 C132.887998,18.6580005 132.585001,18.7869992 132.387,18.949 C132.188999,19.1110008 132.09,19.3359986 132.09,19.624 C132.09,19.9120014 132.179999,20.1309992 132.36,20.281 C132.540001,20.4310007 132.791998,20.506 133.116,20.506 Z M145.734,12.82 C146.934006,12.82 147.875997,13.2339959 148.56,14.062 C149.244003,14.8900041 149.586,16.0419926 149.586,17.518 C149.586,18.9820073 149.244003,20.1249959 148.56,20.947 C147.875997,21.7690041 146.934006,22.18 145.734,22.18 C145.025996,22.18 144.411003,22.0030018 143.889,21.649 C143.366997,21.2949982 142.974001,20.818003 142.71,20.218 L142.62,22 L140.442,22 L140.442,9.058 L142.908,9.058 L142.908,14.476 C143.184001,13.9599974 143.561998,13.5550015 144.042,13.261 C144.522002,12.9669985 145.085997,12.82 145.734,12.82 Z M144.996,20.29 C145.668003,20.29 146.189998,20.0500024 146.562,19.57 C146.934002,19.0899976 147.12,18.4000045 147.12,17.5 C147.12,16.5999955 146.934002,15.9100024 146.562,15.43 C146.189998,14.9499976 145.668003,14.71 144.996,14.71 C144.395997,14.71 143.910002,14.9199979 143.538,15.34 C143.165998,15.7600021 142.956,16.3479962 142.908,17.104 L142.908,17.896 C142.956,18.6640038 143.165998,19.2549979 143.538,19.669 C143.910002,20.0830021 144.395997,20.29 144.996,20.29 Z M157.056,12.82 C158.256006,12.82 159.197997,13.2339959 159.882,14.062 C160.566003,14.8900041 160.908,16.0419926 160.908,17.518 C160.908,18.9820073 160.566003,20.1249959 159.882,20.947 C159.197997,21.7690041 158.256006,22.18 157.056,22.18 C156.347996,22.18 155.733003,22.0030018 155.211,21.649 C154.688997,21.2949982 154.296001,20.818003 154.032,20.218 L153.942,22 L151.764,22 L151.764,9.058 L154.23,9.058 L154.23,14.476 C154.506001,13.9599974 154.883998,13.5550015 155.364,13.261 C155.844002,12.9669985 156.407997,12.82 157.056,12.82 Z M156.318,20.29 C156.990003,20.29 157.511998,20.0500024 157.884,19.57 C158.256002,19.0899976 158.442,18.4000045 158.442,17.5 C158.442,16.5999955 158.256002,15.9100024 157.884,15.43 C157.511998,14.9499976 156.990003,14.71 156.318,14.71 C155.717997,14.71 155.232002,14.9199979 154.86,15.34 C154.487998,15.7600021 154.278,16.3479962 154.23,17.104 L154.23,17.896 C154.278,18.6640038 154.487998,19.2549979 154.86,19.669 C155.232002,20.0830021 155.717997,20.29 156.318,20.29 Z M164.328,11.704 C163.307995,11.704 162.798,11.2660044 162.798,10.39 C162.798,9.50199556 163.307995,9.058 164.328,9.058 C165.348005,9.058 165.858,9.50199556 165.858,10.39 C165.858,11.2660044 165.348005,11.704 164.328,11.704 Z M165.552,22 L163.086,22 L163.086,13 L165.552,13 L165.552,22 Z M174.336,21.442 C174.047999,21.6700011 173.685002,21.8499993 173.247,21.982 C172.808998,22.1140007 172.350002,22.18 171.87,22.18 C169.86599,22.18 168.864,21.2740091 168.864,19.462 L168.864,14.836 L167.226,14.836 L167.226,13 L168.864,13 L168.864,10.93 L171.33,10.246 L171.33,13 L174.246,13 L174.246,14.836 L171.33,14.836 L171.33,19.066 C171.33,19.8940041 171.743996,20.308 172.572,20.308 C173.100003,20.308 173.561998,20.1400017 173.958,19.804 L174.336,21.442 Z" id="VowpalWabbit" fill="#333333" fill-rule="nonzero"></path>
                <g id="logo_vw_color" transform="translate(3.000000, 0.000000)" fill="#2A3B93">
                    <path d="M27.9875518,16.6117194 C27.9875518,9.21947752 21.9666728,9.36035971 21.9666728,9.36035971 C21.3736977,6.15536974 20.3362508,3.5963294 19.3414955,1.96947553 C18.1790857,0.436543115 17.3241355,0 17.3241355,0 C16.2887633,0.700737156 15.7766231,3.93943024 15.7766231,3.93943024 C14.1726939,1.18184505 12.329851,1.05294263 12.329851,1.05294263 C9.93824094,8.37466357 17.0427696,11.1203489 17.0427696,11.1203489 C9.97542657,11.1203489 6.33307087,15.0400524 4.59284756,17.9877167 C4.0042614,19.0524794 3.60319929,20.0302689 3.35048069,20.7371557 L2.99801525,21.8605394 C1.89952322,21.2108361 0.011355398,21.1878349 0.011355398,21.1878349 C-0.278708419,29.2136474 5.0845596,28.0167877 5.0845596,28.0167877 C5.0845596,29.1432063 6.56177043,30 6.56177043,30 L18.0978518,30 C18.0978518,30 17.9248509,28.5478912 16.7183131,27.7616983 C16.5196972,27.4693917 16.4533057,27.212705 16.6897456,26.9422016 C17.354698,26.1816454 17.8296525,27.1798804 17.8296525,27.1798804 L18.3302221,27.8553801 C19.7539686,29.627988 20.7440159,29.9516816 21.1646284,30 L21.391732,30 C20.5763614,27.5009384 20.6054875,25.3190215 20.6054875,25.3190215 C20.4822802,22.1365535 22.8107704,19.2166024 22.8107704,19.2166024 C28.5084697,19.2166024 27.9875518,16.6117194 27.9875518,16.6117194" id="logo_rabbit"></path>
                </g>
            </g>
        </g>
    </g>
</svg>
      </a>
    </div>
  </div>
</div>

<div class="mobile_nav">
  <button type="button" class="go_back_button">
    <
  </button>

  <a href="/start.html" class=''>
    Get started
  </a>
  <a
    href="/features.html"
    class=''
  >
    Features
  </a>
  <a href="/tutorials.html" class='active'>
    Tutorials
  </a>
  <a
    href="/blog.html"
    class=''
  >
    Blog
  </a>
  <a href="/research.html" class=''>
    Research
  </a>
  <div class="external_links">
    <a
      href="https://github.com/VowpalWabbit/vowpalwabbit.github.io/issues/new"
      target="_blank"
    >
      Feedback
    </a>

    <a href="https://github.com/VowpalWabbit/vowpal_wabbit/wiki" target="_blank">
      Wiki
    </a>

    <a href="https://github.com/VowpalWabbit/vowpal_wabbit" target="_blank" class="github_link">
      <?xml version="1.0" encoding="UTF-8"?>
<svg width="30px" height="30px" viewBox="0 0 30 30" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
    <!-- Generator: Sketch 53 (72520) - https://sketchapp.com -->
    <title>GitHub</title>
    <desc>Created with Sketch.</desc>
    <g id="Symbols" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
        <g id="HD_Desktop_header_Home" transform="translate(-1538.000000, -58.000000)" fill="#FFFFFF">
            <g id="Header">
                <path d="M1568,73.7951128 C1567.94603,74.2583723 1567.89891,74.7224863 1567.83682,75.1847206 C1567.56271,77.2238487 1566.86543,79.1138828 1565.7732,80.8526868 C1564.55268,82.7956941 1562.9969,84.4188114 1561.05088,85.6538569 C1560.03339,86.2996179 1558.94817,86.8066231 1557.80753,87.1895684 C1557.17559,87.4016322 1556.73848,87.0743943 1556.73531,86.4093237 C1556.72907,85.1020808 1556.73745,83.7947524 1556.73164,82.487424 C1556.72804,81.6908602 1556.64825,80.9063436 1556.21259,80.2087201 C1556.0855,80.0052003 1555.92463,79.8226135 1555.77393,79.6234512 C1556.35935,79.5140871 1556.9463,79.4362506 1557.51632,79.2916849 C1559.04696,78.9034423 1560.41543,78.2275208 1561.34791,76.8924242 C1562.03287,75.9115647 1562.34632,74.7851144 1562.48436,73.6108172 C1562.59169,72.6982249 1562.62222,71.7826422 1562.42971,70.8740656 C1562.23608,69.9599354 1561.84044,69.1418405 1561.22834,68.4359293 C1561.07756,68.2620575 1561.04763,68.1215929 1561.12221,67.896713 C1561.52468,66.6818314 1561.3562,65.491984 1560.9042,64.3262309 C1560.87829,64.2595017 1560.76574,64.1973008 1560.68569,64.1853391 C1560.15364,64.1058793 1559.65196,64.2559986 1559.18533,64.4761793 C1558.42904,64.8332361 1557.69764,65.242668 1556.9487,65.6159585 C1556.82229,65.6790137 1556.64782,65.7219904 1556.51706,65.6889249 C1554.16941,65.0964789 1551.82595,65.097077 1549.47805,65.6883268 C1549.34078,65.7228448 1549.14638,65.677134 1549.02331,65.5987849 C1548.07109,64.9919849 1547.06446,64.5120644 1545.97001,64.2236166 C1545.9511,64.218661 1545.93272,64.2115694 1545.91364,64.2077246 C1545.22551,64.0670892 1545.09971,64.1456947 1544.9036,64.8108506 C1544.58682,65.884755 1544.5296,66.9550708 1544.90668,68.0296587 C1544.93627,68.1139033 1544.90129,68.2616303 1544.8404,68.3306664 C1543.60397,69.7341156 1543.31096,71.3989279 1543.46559,73.1936101 C1543.55933,74.2817831 1543.81162,75.3262104 1544.29869,76.3083514 C1544.97176,77.6654063 1546.11181,78.4952066 1547.4926,78.982475 C1548.35956,79.2884382 1549.27852,79.4473579 1550.18824,79.6758264 C1550.19526,79.6319098 1550.20056,79.6666842 1550.18568,79.6820635 C1549.71726,80.1697591 1549.45556,80.755028 1549.34531,81.4170227 C1549.33137,81.5007546 1549.27365,81.6203716 1549.20685,81.6454912 C1548.16482,82.0372369 1547.11706,82.2433199 1546.08683,81.6149888 C1545.61867,81.3295314 1545.27683,80.9169382 1545.00101,80.4479541 C1544.56852,79.712395 1543.95864,79.179074 1543.13923,78.9361661 C1542.84434,78.8487602 1542.50823,78.8709748 1542.19359,78.8892591 C1541.97909,78.9018189 1541.90862,79.062362 1542.05256,79.2422147 C1542.18529,79.4077988 1542.32025,79.5950849 1542.4978,79.6971865 C1543.28625,80.1507913 1543.72798,80.8753286 1544.08881,81.6641173 C1544.30382,82.1341266 1544.48812,82.6140471 1544.88675,82.9753759 C1545.52169,83.5510755 1546.29115,83.7682658 1547.11612,83.8044072 C1547.81434,83.834995 1548.51496,83.8107298 1549.24722,83.8107298 C1549.24611,83.8009041 1549.26073,83.8742123 1549.26167,83.9476058 C1549.27211,84.7377616 1549.2828,85.5279173 1549.28844,86.3180731 C1549.294,87.0913115 1548.82935,87.4109452 1548.0952,87.1563319 C1544.28705,85.8355039 1541.4928,83.3342269 1539.62819,79.7992882 C1538.22405,77.1372118 1537.78027,74.2780237 1538.09739,71.2935795 C1538.4294,68.1688416 1539.66702,65.4337134 1541.73193,63.0872551 C1543.89022,60.6347648 1546.57714,59.0045559 1549.78825,58.3523869 C1554.45335,57.4048494 1558.71409,58.3562318 1562.44442,61.3515269 C1565.27245,63.6222848 1567.02271,66.5767393 1567.72914,70.1361141 C1567.83314,70.6605492 1567.87265,71.197715 1567.94398,71.7286436 C1567.95792,71.832625 1567.9811,71.9354102 1568,72.0387934 L1568,73.7951128 Z" id="GitHub"></path>
            </g>
        </g>
    </g>
</svg>
      <div>
        GitHub
      </div>
    </a>
  </div>
</div>

<script src="/assets/js/header.js"></script>


    <div class="hero">
      <div class="container">
        <div class="row">
          <div class="col-lg-6">
            <h1>
              Tutorials
            </h1>
            <a href="/tutorials.html">
              < Back to all tutorials
            </a>
          </div>
        </div>
      </div>
    </div>

    <div class="container content tutorial_container">
      <div class="edit">
  
  

  <a href="https://github.com/VowpalWabbit/vowpalwabbit.github.io/blob/source/_tutorials/contextual_bandits.md" target="_blank">
    <?xml version="1.0" encoding="UTF-8"?>
<svg width="16px" height="16px" viewBox="0 0 16 16" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
    <!-- Generator: Sketch 57.1 (83088) - https://sketch.com -->
    <title>icon_edit</title>
    <desc>Created with Sketch.</desc>
    <g id="Symbols" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
        <g id="button_edit" transform="translate(-7.000000, -7.000000)" stroke="#2A3B93">
            <g id="icon_edit_selected">
                <g transform="translate(8.000000, 8.000000)">
                    <path d="M3.99393054,13.0502777 C0,14.1182229 0,14.1182229 0,14.1182229 C1.01972686,10.1881871 1.01972686,10.1881871 1.01972686,10.1881871 C10.579668,0.576689783 10.579668,0.576689783 10.579668,0.576689783 C11.3869519,-0.192229928 12.661609,-0.192229928 13.4264041,0.576689783 C14.1911991,1.34560988 14.1911991,2.62714261 13.4264041,3.43878036 L3.99393054,13.0502777 Z M9.85736179,1.30289223 C12.7465867,4.16498242 12.7465867,4.16498242 12.7465867,4.16498242 L9.85736179,1.30289223 Z M3.99393054,13.0502777 C3.99393054,13.0502777 4.16388585,12.0677717 3.14415784,10.9143911 C2.12443098,9.7610106 1.01972686,10.1881871 1.01972686,10.1881871" id="icon_edit"></path>
                </g>
            </g>
        </g>
    </g>
</svg>
    <div class="text">
      Edit on GitHub
    </div>
  </a>
</div>

      <div class="row">
        <div class="col-lg-3">
          <div class="tutorial_nav">
            <ul class="tutorial_content_nav">
              <li class="label">
                Table of contents
              </li>
            </ul>
            
              <div class="run_tutorial_links">
                <ul>
                  <li class="label">
                    Run this tutorial
                  </li>
                  <li>
                    <span>
                      <a
                        href="https://github.com/VowpalWabbit/jupyter-notebooks/blob/master/Contextual_bandits_and_Vowpal_Wabbit.ipynb"
                        target="_blank"
                      >
                        GitHub source file
                      </a>
                    </span>
                  </li>
                  <li>
                    <span>
                      <a
                        href="https://mybinder.org/v2/gh/VowpalWabbit/jupyter-notebooks/master?filepath=Contextual_bandits_and_Vowpal_Wabbit.ipynb"
                        target="_blank"
                      >
                        Jupyter Notebook
                      </a>
                    </span>
                  </li>
                </ul>
              </div>
            
          </div>
        </div>
        <div class="col-lg-9">
          <h1 id="contextual-bandits-reinforcement-learning-with-vowpal-wabbit">Contextual Bandits Reinforcement Learning with Vowpal Wabbit</h1>

<p>This tutorial includes a brief overview of reinforcement learning, the contextual bandits approach to this machine learning paradigm, and describes how to approach a contextual bandits problem with Vowpal Wabbit. No prior knowledge of contextual bandits, reinforcement learning, or Vowpal Wabbit is required.</p>

<div class="prerequisites">
  <p><strong>Prerequisites</strong></p>

  <p>To install Vowpal Wabbit see <a href="../start.html">Get Started</a>.</p>

  <blockquote>
    <p><strong>Note</strong> The contextual bandits tutorial uses <a href="https://github.com/VowpalWabbit/vowpal_wabbit/tree/master/python">Vowpal Wabbit Python package</a>. Additional binary packages are available for select platforms.</p>
  </blockquote>
</div>

<h2 id="getting-started">Getting started</h2>

<p>If you are familiar with reinforcement learning and ready to start using Vowpal Wabbit in a contextual bandit setting, please see <a href="contextual_bandits.html#part-two">Part Two</a> tutorial. This section includes a Python tutorial, information for how to work with Vowpal Wabbit contextual bandits approaches, how to format data, and understand the results.</p>

<h2 id="what-is-reinforcement-learning">What is reinforcement learning?</h2>

<p><a href="https://docs.microsoft.com/en-us/azure/cognitive-services/personalizer/concepts-reinforcement-learning" target="blank">Reinforcement learning</a> is a machine learning paradigm used to train models for sequential decision making. It involves using algorithms concerned with how a software agent takes suitable actions in complex environments and uses the feedback to maximize reward over time. This approach provides the freedom to enact specific user behavior, in a given context, and provide feedback on how the chosen behavior is rewarded based on the goal.</p>

<h2 id="the-contextual-bandits-approach">The contextual bandits approach</h2>

<p>Vowpal Wabbit founder John Langford coined the term <a href="http://hunch.net/~jl/projects/interactive/sidebandits/bandit.pdf" target="blank">contextual bandits</a> to describe a flexible subset of reinforcement learning. The contextual bandit approach to reinforcement learning frames decision-making (choices) between separate actions in a given context.</p>

<p>The Microsoft Azure cloud-based API service <a href="https://azure.microsoft.com/en-us/services/cognitive-services/personalizer/" target="blank">Personalizer</a> uses a bandit approach to reinforcement learning to help choose the best experience to show users — learning from real-time behavior to make choices between discrete actions in a given context.</p>

<h2 id="the-contextual-bandits-problem">The contextual bandits problem</h2>

<p>In the contextual bandit problem, a learner repeatedly observes a context, chooses an action, and observes a loss/cost/reward for the chosen action only. Contextual bandits algorithms use additional side information (or context) to aid real-world decision-making <sup><a class="cite_sup" href="#DBLP:journals/corr/AgarwalBCHLLLMO16">[1]</a> <a class="cite_sup" href="#DBLP:journals/corr/abs-1003-0146">[2]</a></sup>. They work well for choosing actions in dynamic environments where options change rapidly, and the set of available actions is limited.</p>

<p>The standard k-armed bandits problem, or multi-armed bandits problem, is well-studied in the research literature. It is regarded as a repeated game between two players, with every stage consisting of the following:</p>

<ul>
  <li><strong>Step One:</strong> The world chooses k rewards r1, …, rk ∈ [0, 1].</li>
  <li><strong>Step Two:</strong> The player chooses an arm i ∈ {1, k} without knowledge of the world’s chosen rewards.</li>
  <li><strong>Step Three:</strong> The player observes the reward ri.</li>
</ul>

<p>The contextual bandits setting considered in part two of this tutorial is the same except for the second step, in which the player also observes context information x (which is used to determine which arm to pull). Vowpal Wabbit’s default algorithm for this type of exploration is <a href="http://hunch.net/~jl/projects/interactive/sidebandits/bandit.pdf" target="blank">Epsilon-Greedy</a>.</p>

<p>The contextual bandits problem is more suitable than the standard bandits problem because settings with no context information are rare in practice. For more on the research behind contextual bandits and this approach to Vowpal Wabbit reinforcement learning, see <a href="../research.html">Research</a>.</p>

<h2 id="part-two">Part Two</h2>

<p>Vowpal Wabbit is an interactive machine learning library and the reinforcement learning framework for services like <a href="https://azure.microsoft.com/en-us/services/cognitive-services/personalizer/" target="blank">Microsoft Personalizer</a>. It allows for maximum throughput and lowest latency when making personalization ranks and training the model with all events. For more on the Vowpal Wabbit framework, including a tutorial for simulating web content personalization, see <a href="cb_simulation.html">Content Personalization with Contextual Bandits</a>.</p>

<h2 id="vowpal-wabbit-tutorial">Vowpal Wabbit tutorial</h2>

<p>This tutorial uses an application example we’ll call <strong>APP</strong> to introduce a Vowpal Wabbit approach to the contextual bandit problem and explore the capabilities of this reinforcement learning approach. The problem scenario of web content personalization motivates our example  <strong>APP</strong>. The goal is to show the user the most relevant web content on each page to maximize engagement (clicks).</p>

<h3 id="working-with-contextual-bandits">Working with contextual bandits</h3>

<p><strong>APP</strong> interacts with the context of a user’s behavior (search history, visited pages, or geolocation) in a dynamic environment – such as a news website or a cloud controller. <strong>APP</strong> differs from the multi-armed bandits problem because we have some information available to the <strong>APP</strong>, which is the context.</p>

<p><strong>APP</strong> performs the following functions:</p>

<ul>
  <li>Some context <strong>x</strong> arrives and is observed by <strong>APP</strong>.</li>
  <li><strong>APP</strong> chooses an action <strong>a</strong> from a set of actions <strong>A</strong>, i.e., <strong>a</strong> ∈ <strong>A</strong> (<strong>A</strong> may depend on <strong>x</strong>).</li>
  <li>Some reward <strong>r</strong> for the chosen <strong>a</strong> is observed by <strong>APP</strong>.</li>
</ul>

<p><strong>For example:</strong></p>

<p><strong>APP</strong> news website:</p>

<ul>
  <li><strong>Decision to optimize</strong>: articles to display to user.</li>
  <li><strong>Context</strong>: user data (browsing history, location, device, time of day)</li>
  <li><strong>Actions</strong>: available news articles</li>
  <li><strong>Reward</strong>: user engagement (click or no click)</li>
</ul>

<p><strong>APP</strong> cloud controller:</p>
<ul>
  <li><strong>Decision to optimize</strong>: the wait time before reboot of unresponsive machine.</li>
  <li><strong>Context</strong>: the machine hardware specs (SKU, OS, failure history, location, load).</li>
  <li><strong>Actions</strong>: time in minutes - {1 ,2 , …N}</li>
  <li><strong>Reward</strong>: negative of the total downtime</li>
</ul>

<p>You want  <strong>APP</strong> to take actions that provide the highest possible reward. In machine learning parlance, we want a <strong>model</strong> that tells us which action to take.</p>

<h3 id="policy-vs-model">Policy vs. model</h3>

<p>We use the term <strong>policy</strong> many times in this tutorial. In reinforcement learning, the policy is roughly equivalent to <strong>model</strong>. In machine learning, the model means <strong>learned function</strong>. When someone says policy, it is more specific than model because it indicates this is a model that acts in the world.</p>

<p>Contexts and actions are typically represented as feature vectors in contextual bandit algorithms. For example, <strong>APP</strong> chooses actions by applying a policy <strong>π</strong> that takes a context as input and returns an action. The goal is to find a policy that maximizes the average reward over a sequence of interactions.</p>

<h3 id="specify-the-approach">Specify the approach</h3>

<p>There are multiple policy evaluation approaches available to optimize a policy. Vowpal Wabbit offers four approaches to specify a contextual bandit approach using <code class="highlighter-rouge">--cb_type</code>:</p>

<ul>
  <li><strong>Inverse Propensity Score</strong><sup><a class="cite_sup" href="#doi:10.1080/01621459.1952.10483446">[3]</a></sup>: <code class="highlighter-rouge">--cb_type ips</code></li>
  <li><strong>Doubly Robust</strong><sup><a class="cite_sup" href="#DBLP:conf/icml/JiangL16">[4]</a> <a class="cite_sup" href="#DBLP:conf/icml/DudikLL11">[5]</a></sup>: <code class="highlighter-rouge">--cb_type dr</code></li>
  <li><strong>Direct Method</strong>: <code class="highlighter-rouge">--cb_type dm</code></li>
  <li><strong>Multi Task Regression/Importance Weighted Regression</strong><sup><a class="cite_sup" href="#bietti2018a">[6]</a> <a class="cite_sup" href="#Karampatziakis:2011:OIW:3020548.3020594">[7]</a></sup>: <code class="highlighter-rouge">--cb_type mtr</code></li>
</ul>

<blockquote>
  <p><strong>Note:</strong> The focal point of contextual bandit learning research is efficient exploration algorithms. For more details, see the <a href="https://arxiv.org/pdf/1802.04064.pdf" target="blank">Contextual Bandit bake-off paper</a>.</p>
</blockquote>

<h3 id="specifying-exploration">Specifying exploration</h3>

<p>Vowpal Wabbit offers five exploration algorithms:</p>

<ul>
  <li><strong>Explore-First</strong><sup><a class="cite_sup" href="#DBLP:journals/corr/OsbandR15">[8]</a> <a class="cite_sup" href="#DBLP:journals/corr/EcklesK14">[9]</a></sup>: <code class="highlighter-rouge">--first</code></li>
  <li><strong>Epsilon-Greedy</strong>: <code class="highlighter-rouge">--epsilon</code></li>
  <li><strong>Bagging Explorer</strong>: <code class="highlighter-rouge">--bag</code></li>
  <li><strong>Online Cover</strong><sup><a class="cite_sup" href="#DBLP:journals/corr/AgarwalHKLLS14">[10]</a></sup>: <code class="highlighter-rouge">--cover</code></li>
  <li><strong>Softmax Explorer</strong><sup><a class="cite_sup" href="#DBLP:journals/corr/abs-1811-04383">[11]</a></sup>: <code class="highlighter-rouge">--softmax</code> (only supported for <code class="highlighter-rouge">--cb_explore_adf</code>)</li>
</ul>

<blockquote>
  <p><strong>Note:</strong> For more details on contextual bandits algorithms and Vowpal Wabbit, please refer to the <a href="https://github.com/VowpalWabbit/vowpal_wabbit/wiki/Contextual-Bandit-algorithms" target="blank">Vowpal Wabbit Github Wiki</a>.</p>
</blockquote>

<h2 id="algorithms-and-format">Algorithms and format</h2>

<p>There are four main components to a contextual bandit problem:</p>

<ul>
  <li><strong>Context (x)</strong>: the additional information which helps in choosing action.</li>
  <li><strong>Action (a)</strong>: the action chosen from a set of possible actions <strong>A</strong>.</li>
  <li><strong>Probability (p)</strong>: the probability of choosing <strong>a</strong> from <strong>A</strong>.</li>
  <li><strong>Cost/Reward (r)</strong>: the reward received for action <strong>a</strong>.</li>
</ul>

<p>Vowpal Wabbit provides three contextual bandits algorithms:</p>

<ol>
  <li><code class="highlighter-rouge">--cb</code>
  The contextual bandit module which allows you to optimize predictor based on already collected data, or contextual bandits without exploration.</li>
  <li><code class="highlighter-rouge">--cb_explore</code>
  The contextual bandit learning algorithm for when the maximum number of actions is known ahead of time and semantics of actions stays the same across examples.</li>
  <li><code class="highlighter-rouge">--cb_adf</code> and <code class="highlighter-rouge">--cb_explore_adf</code>
  The contextual bandit learning algorithm for when the set of actions changes over time or you have rich information for each action.</li>
</ol>

<p>Vowpal Wabbit offers different input formats for contextual bandits. Below we are going over main differences and unique capbilities.</p>

<h3 id="input-format-for---cb">Input format for <code class="highlighter-rouge">--cb</code></h3>

<p>The <code class="highlighter-rouge">--cb 4</code> command specifies that we want to use the contextual bandit module, and our data has a total of four actions:</p>

<div class="language-text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>--cb &lt;number_of_actions&gt;
</code></pre></div></div>

<p>Each example is represented as a separate line in your data file and must follow the following format:</p>

<div class="language-text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>action:cost:probability | features
</code></pre></div></div>

<p>Sample data file <strong>train.dat</strong> with five examples:</p>

<div class="language-text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>1:2:0.4 | a c
3:0.5:0.2 | b d
4:1.2:0.5 | a b c
2:1:0.3 | b c
3:1.5:0.7 | a d
</code></pre></div></div>

<p><strong>Use the command:</strong></p>

<div class="language-text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>vw -d train.dat --cb 4
</code></pre></div></div>

<blockquote>
  <p><strong>Note:</strong> This usage is for the Vowpal Wabbit command line. See below for a Python tutorial.</p>
</blockquote>

<h3 id="input-format-for---cb_explore">Input format for <code class="highlighter-rouge">--cb_explore</code></h3>

<p>The command <code class="highlighter-rouge">--cb_explore 4</code> specifies our examples explore a total of four actions:</p>

<div class="language-text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>--cb_explore &lt;number_of_actions&gt;
</code></pre></div></div>

<blockquote>
  <p><strong>Note:</strong> This format explores the action space so you must specify which algorithm you want to use for exploration.</p>
</blockquote>

<h3 id="usage">Usage</h3>

<p>The following examples use the input format from the <code class="highlighter-rouge">--cb</code> command example:</p>

<div class="language-text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>vw -d train.dat --cb_explore 4 --first 2
</code></pre></div></div>

<p>In this case, on the first two actions, you take each of the four actions with probability 1/4.</p>

<div class="language-text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>vw -d train.dat --cb_explore 4 --epsilon 0.2
</code></pre></div></div>

<p>In this case, the prediction of the current learned policy takes with probability <strong>1 - epsilon</strong> 80% of the time, and with the remaining 20% epsilon probability, an action is chosen uniformly at random.</p>

<div class="language-text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>vw -d train.dat --cb_explore 4 --bag 5
</code></pre></div></div>

<div class="language-text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>vw -d train.dat --cb_explore 4 --cover 3
</code></pre></div></div>

<p>This algorithm is a theoretically optimal exploration algorithm. Similar to the previous bagging <strong>m</strong> example, different policies are trained in this case. Unlike bagging, the training of these policies is explicitly optimized to result in a diverse set of predictions — choosing all the actions which are not already learned to be bad in a given context.</p>

<p>For more information and research on this theoretically optimal exploration algorithm see <a href="http://arxiv.org/abs/1402.0555" target="blank">Taming the Monster: A Fast and Simple Algorithm for Contextual Bandits</a>.</p>

<h3 id="input-format-for---cb_adf-or---cb_explore_adf---action-dependent-features">Input format for <code class="highlighter-rouge">--cb_adf</code> or <code class="highlighter-rouge">--cb_explore_adf</code> - Action Dependent Features</h3>

<p>In <code class="highlighter-rouge">--cb</code> and <code class="highlighter-rouge">--cb_explore</code> the action set is fixed, and each action is described by an index (i.e., actions have no features). These two limitations are addressed in the commands <code class="highlighter-rouge">--cb_adf</code> and <code class="highlighter-rouge">--cb_explore_adf</code>. In these action depended features versions the action set can change over time and/or we have features for each action. Key properties of this format are:</p>

<ul>
  <li>Each example now spans multiple lines. Each line describes one action, and a new line signals the end of a multiline example.</li>
  <li>For the chosen action, we have the label information (action, cost, probability).</li>
  <li>The action field <strong>a</strong> is ignored (so it is typically set to 0) since the actions are explicitly described in each line.</li>
  <li>The semantics of cost and probability are the same as before.</li>
</ul>

<p>It’s best to create features for every (context, action) pair rather than features associated only with context and shared across all actions.</p>

<div class="language-text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>--cb_explore_adf
</code></pre></div></div>

<blockquote>
  <p><strong>Note:</strong> This format explores the action space so you must specify which algorithm you want to use for exploration.</p>
</blockquote>

<h3 id="shared-contextual-features">Shared contextual features</h3>

<p>You can specify contextual features which share all line actions at the beginning of an example, which always has a <code class="highlighter-rouge">shared</code> label, as in the second multiline example below.</p>

<p>Since the shared line is not associated with any action, it should never contain the label information.</p>

<p>Sample data file <strong>train.dat</strong> with two examples:</p>

<div class="language-text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>| a:1 b:0.5
0:0.1:0.75 | a:0.5 b:1 c:2

shared | s_1 s_2
0:1.0:0.5 | a:1 b:1 c:1
| a:0.5 b:2 c:1
</code></pre></div></div>

<p>In the first example, we have two actions, one line for each. The first line represents the first action, and it has two action dependent features <strong>a</strong> and <strong>b</strong>.</p>

<div class="language-text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>| a:1 b:0.5
</code></pre></div></div>

<p>The second line represents the second action, and it has three action dependent features <strong>a</strong>, <strong>b</strong>, and <strong>c</strong>.</p>

<div class="language-text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>0:0.1:0.75 | a:0.5 b:1 c:2
</code></pre></div></div>

<p>If the second action is the chosen action it follows the following format:</p>

<div class="language-text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>action:cost:probability | features
0:0.1:0.75 |
</code></pre></div></div>
<p>Action 0 is ignored, has cost 0.1 and a probability of 0.75.</p>

<h3 id="usage-1">Usage</h3>

<p>In the case of the softmax explorer, which uses the policy not only to predict an action but also predict a score indicating the quality of each action. The probability of action <strong>a</strong> creates distribution proportional to <strong>exp(lambda * score(x, a))</strong>.</p>

<div class="language-text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>vw -d train_adf.dat --cb_explore_adf
</code></pre></div></div>

<div class="language-text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>vw -d train.dat --cb_explore_adf --first 2
</code></pre></div></div>

<div class="language-text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>vw -d train.dat --cb_explore_adf --epsilon 0.1
</code></pre></div></div>

<div class="language-text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>vw -d train.dat --cb_explore_adf --bag 5
</code></pre></div></div>

<div class="language-text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>vw -d train.dat --cb_explore_adf --softmax --lambda 10
</code></pre></div></div>

<p>Here <strong>lambda</strong> is a parameter, which leads to uniform exploration for <strong>lambda = 0</strong>, and stops exploring as <strong>lambda</strong> approaches infinity. In general, this provides an excellent knob for controlled exploration based on the uncertainty in the learned policy.</p>

<h2 id="create-contextual-bandit-data">Create contextual bandit data</h2>

<p>First, import the required Python packages:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">sklearn</span> <span class="k">as</span> <span class="n">sk</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
</code></pre></div></div>

<p>Next, install <a href="https://github.com/VowpalWabbit/vowpal_wabbit/tree/master/python" target="blank">Vowpal Wabbit Python package</a>:</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pip <span class="nb">install </span>boost
apt-get <span class="nb">install </span>libboost-program-options-dev zlib1g-dev libboost-python-dev <span class="nt">-y</span>
pip <span class="nb">install </span>vowpalwabbit
</code></pre></div></div>

<p>Now, generate some sample training data that could originate from previous random trial (for example A/B test) for the contextual bandit to explore:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">train_data</span> <span class="o">=</span> <span class="p">[{</span><span class="s">'action'</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s">'cost'</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="s">'probability'</span><span class="p">:</span> <span class="mf">0.4</span><span class="p">,</span> <span class="s">'feature1'</span><span class="p">:</span> <span class="s">'a'</span><span class="p">,</span> <span class="s">'feature2'</span><span class="p">:</span> <span class="s">'c'</span><span class="p">,</span> <span class="s">'feature3'</span><span class="p">:</span> <span class="s">''</span><span class="p">},</span>
              <span class="p">{</span><span class="s">'action'</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span> <span class="s">'cost'</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="s">'probability'</span><span class="p">:</span> <span class="mf">0.2</span><span class="p">,</span> <span class="s">'feature1'</span><span class="p">:</span> <span class="s">'b'</span><span class="p">,</span> <span class="s">'feature2'</span><span class="p">:</span> <span class="s">'d'</span><span class="p">,</span> <span class="s">'feature3'</span><span class="p">:</span> <span class="s">''</span><span class="p">},</span>
              <span class="p">{</span><span class="s">'action'</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span> <span class="s">'cost'</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s">'probability'</span><span class="p">:</span> <span class="mf">0.5</span><span class="p">,</span> <span class="s">'feature1'</span><span class="p">:</span> <span class="s">'a'</span><span class="p">,</span> <span class="s">'feature2'</span><span class="p">:</span> <span class="s">'b'</span><span class="p">,</span> <span class="s">'feature3'</span><span class="p">:</span> <span class="s">''</span><span class="p">},</span>
              <span class="p">{</span><span class="s">'action'</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="s">'cost'</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s">'probability'</span><span class="p">:</span> <span class="mf">0.3</span><span class="p">,</span> <span class="s">'feature1'</span><span class="p">:</span> <span class="s">'a'</span><span class="p">,</span> <span class="s">'feature2'</span><span class="p">:</span> <span class="s">'b'</span><span class="p">,</span> <span class="s">'feature3'</span><span class="p">:</span> <span class="s">'c'</span><span class="p">},</span>
              <span class="p">{</span><span class="s">'action'</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span> <span class="s">'cost'</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s">'probability'</span><span class="p">:</span> <span class="mf">0.7</span><span class="p">,</span> <span class="s">'feature1'</span><span class="p">:</span> <span class="s">'a'</span><span class="p">,</span> <span class="s">'feature2'</span><span class="p">:</span> <span class="s">'d'</span><span class="p">,</span> <span class="s">'feature3'</span><span class="p">:</span> <span class="s">''</span><span class="p">}]</span>

<span class="n">train_df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">train_data</span><span class="p">)</span>

<span class="c1"># Add index to data frame
</span><span class="n">train_df</span><span class="p">[</span><span class="s">'index'</span><span class="p">]</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_df</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">train_df</span> <span class="o">=</span> <span class="n">train_df</span><span class="p">.</span><span class="n">set_index</span><span class="p">(</span><span class="s">"index"</span><span class="p">)</span>
</code></pre></div></div>

<blockquote>
  <p><strong>Note:</strong> The data here is equivalent to this <a href="https://github.com/VowpalWabbit/vowpal_wabbit/wiki/Logged-Contextual-Bandit-Example" target="blank">Vowpal Wabbit wiki example</a>.</p>
</blockquote>

<p>Next, create data for the contextual bandit to exploit to make decisions (for example features describing new users):</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">test_data</span> <span class="o">=</span> <span class="p">[{</span><span class="s">'feature1'</span><span class="p">:</span> <span class="s">'b'</span><span class="p">,</span> <span class="s">'feature2'</span><span class="p">:</span> <span class="s">'c'</span><span class="p">,</span> <span class="s">'feature3'</span><span class="p">:</span> <span class="s">''</span><span class="p">},</span>
            <span class="p">{</span><span class="s">'feature1'</span><span class="p">:</span> <span class="s">'a'</span><span class="p">,</span> <span class="s">'feature2'</span><span class="p">:</span> <span class="s">''</span><span class="p">,</span> <span class="s">'feature3'</span><span class="p">:</span> <span class="s">'b'</span><span class="p">},</span>
            <span class="p">{</span><span class="s">'feature1'</span><span class="p">:</span> <span class="s">'b'</span><span class="p">,</span> <span class="s">'feature2'</span><span class="p">:</span> <span class="s">'b'</span><span class="p">,</span> <span class="s">'feature3'</span><span class="p">:</span> <span class="s">''</span><span class="p">},</span>
            <span class="p">{</span><span class="s">'feature1'</span><span class="p">:</span> <span class="s">'a'</span><span class="p">,</span> <span class="s">'feature2'</span><span class="p">:</span> <span class="s">''</span><span class="p">,</span> <span class="s">'feature3'</span><span class="p">:</span> <span class="s">'b'</span><span class="p">}]</span>

<span class="n">test_df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">test_data</span><span class="p">)</span>

<span class="c1"># Add index to data frame
</span><span class="n">test_df</span><span class="p">[</span><span class="s">'index'</span><span class="p">]</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_df</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">test_df</span> <span class="o">=</span> <span class="n">test_df</span><span class="p">.</span><span class="n">set_index</span><span class="p">(</span><span class="s">"index"</span><span class="p">)</span>
</code></pre></div></div>

<p>Your dataframes are:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">train_df</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div></div>

<p>Output:</p>

<div class="output">

  <table>
    <thead>
      <tr>
        <th style="text-align: center">index</th>
        <th style="text-align: center">action</th>
        <th style="text-align: center">cost</th>
        <th style="text-align: center">feature1</th>
        <th style="text-align: center">feature2</th>
        <th style="text-align: center">feature3</th>
        <th style="text-align: center">probability</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td style="text-align: center">1</td>
        <td style="text-align: center">1</td>
        <td style="text-align: center">2</td>
        <td style="text-align: center">a</td>
        <td style="text-align: center">c</td>
        <td style="text-align: center"> </td>
        <td style="text-align: center">0.4</td>
      </tr>
      <tr>
        <td style="text-align: center">2</td>
        <td style="text-align: center">3</td>
        <td style="text-align: center">0</td>
        <td style="text-align: center">b</td>
        <td style="text-align: center">d</td>
        <td style="text-align: center"> </td>
        <td style="text-align: center">0.2</td>
      </tr>
      <tr>
        <td style="text-align: center">3</td>
        <td style="text-align: center">4</td>
        <td style="text-align: center">1</td>
        <td style="text-align: center">a</td>
        <td style="text-align: center">b</td>
        <td style="text-align: center"> </td>
        <td style="text-align: center">0.5</td>
      </tr>
      <tr>
        <td style="text-align: center">4</td>
        <td style="text-align: center">2</td>
        <td style="text-align: center">1</td>
        <td style="text-align: center">a</td>
        <td style="text-align: center">b</td>
        <td style="text-align: center">c</td>
        <td style="text-align: center">0.3</td>
      </tr>
      <tr>
        <td style="text-align: center">5</td>
        <td style="text-align: center">3</td>
        <td style="text-align: center">1</td>
        <td style="text-align: center">a</td>
        <td style="text-align: center">d</td>
        <td style="text-align: center"> </td>
        <td style="text-align: center">0.7</td>
      </tr>
    </tbody>
  </table>

</div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">test_df</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div></div>

<p>Output:</p>

<div class="output">

  <table>
    <thead>
      <tr>
        <th style="text-align: center">index</th>
        <th style="text-align: center">feature1</th>
        <th style="text-align: center">feature2</th>
        <th style="text-align: center">feature3</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td style="text-align: center">1</td>
        <td style="text-align: center">b</td>
        <td style="text-align: center">c</td>
        <td style="text-align: center"> </td>
      </tr>
      <tr>
        <td style="text-align: center">2</td>
        <td style="text-align: center">a</td>
        <td style="text-align: center"> </td>
        <td style="text-align: center">b</td>
      </tr>
      <tr>
        <td style="text-align: center">3</td>
        <td style="text-align: center">b</td>
        <td style="text-align: center">b</td>
        <td style="text-align: center"> </td>
      </tr>
      <tr>
        <td style="text-align: center">4</td>
        <td style="text-align: center">a</td>
        <td style="text-align: center"> </td>
        <td style="text-align: center">b</td>
      </tr>
    </tbody>
  </table>

</div>

<h2 id="python-tutorial">Python tutorial</h2>

<p>First, create the Python model store the model parameters in the Python <code class="highlighter-rouge">vw</code> object.</p>

<p>Use the following command for a contextual bandit with four possible actions:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">vowpalwabbit</span> <span class="kn">import</span> <span class="n">pyvw</span>

<span class="n">vw</span> <span class="o">=</span> <span class="n">pyvw</span><span class="p">.</span><span class="n">vw</span><span class="p">(</span><span class="s">"--cb 4"</span><span class="p">)</span>
</code></pre></div></div>

<blockquote>
  <p><strong>Note:</strong> Use <code class="highlighter-rouge">--quiet</code> command to turn off diagnostic information in Vowpal Wabbit.</p>
</blockquote>

<p>Now, call learn for each trained example on your Vowpal Wabbit model:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">train_df</span><span class="p">.</span><span class="n">index</span><span class="p">:</span>
  <span class="n">action</span> <span class="o">=</span> <span class="n">train_df</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="s">"action"</span><span class="p">]</span>
  <span class="n">cost</span> <span class="o">=</span> <span class="n">train_df</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="s">"cost"</span><span class="p">]</span>
  <span class="n">probability</span> <span class="o">=</span> <span class="n">train_df</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="s">"probability"</span><span class="p">]</span>
  <span class="n">feature1</span> <span class="o">=</span> <span class="n">train_df</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="s">"feature1"</span><span class="p">]</span>
  <span class="n">feature2</span> <span class="o">=</span> <span class="n">train_df</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="s">"feature2"</span><span class="p">]</span>
  <span class="n">feature3</span> <span class="o">=</span> <span class="n">train_df</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="s">"feature3"</span><span class="p">]</span>

  <span class="c1"># Construct the example in the required vw format.
</span>  <span class="n">learn_example</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">action</span><span class="p">)</span> <span class="o">+</span> <span class="s">":"</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">cost</span><span class="p">)</span> <span class="o">+</span> <span class="s">":"</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">probability</span><span class="p">)</span> <span class="o">+</span> <span class="s">" | "</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">feature1</span><span class="p">)</span> <span class="o">+</span> <span class="s">" "</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">feature2</span><span class="p">)</span> <span class="o">+</span> <span class="s">" "</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">feature3</span><span class="p">)</span>

  <span class="c1"># Here we do the actual learning.
</span>  <span class="n">vw</span><span class="p">.</span><span class="n">learn</span><span class="p">(</span><span class="n">learn_example</span><span class="p">)</span>
</code></pre></div></div>

<p>Use the model that was just trained on the train set to perform predictions on the test set. Construct the example like before but don’t include the label and pass it into <strong>predict</strong> instead of <strong>learn</strong>.</p>

<p><strong>For example:</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">test_df</span><span class="p">.</span><span class="n">index</span><span class="p">:</span>
  <span class="n">feature1</span> <span class="o">=</span> <span class="n">test_df</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="s">"feature1"</span><span class="p">]</span>
  <span class="n">feature2</span> <span class="o">=</span> <span class="n">test_df</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="s">"feature2"</span><span class="p">]</span>
  <span class="n">feature3</span> <span class="o">=</span> <span class="n">test_df</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="s">"feature3"</span><span class="p">]</span>

  <span class="n">test_example</span> <span class="o">=</span> <span class="s">"| "</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">feature1</span><span class="p">)</span> <span class="o">+</span> <span class="s">" "</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">feature2</span><span class="p">)</span> <span class="o">+</span> <span class="s">" "</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">feature3</span><span class="p">)</span>

  <span class="n">choice</span> <span class="o">=</span> <span class="n">vw</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_example</span><span class="p">)</span>
  <span class="k">print</span><span class="p">(</span><span class="n">j</span><span class="p">,</span> <span class="n">choice</span><span class="p">)</span>
</code></pre></div></div>

<p><strong>Output:</strong></p>

<div class="output">
  <p>1 3
2 3
3 3
4 3</p>
</div>

<blockquote>
  <p><strong>Note:</strong> The contextual bandit assigns every instance to the third action as it should per the cost structure of the train data. You can save and load the model you train from a file.</p>
</blockquote>

<p>Finally, experiment with the cost structure to see that the contextual bandit updates its predictions accordingly:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">vw</span><span class="p">.</span><span class="n">save</span><span class="p">(</span><span class="s">'cb.model'</span><span class="p">)</span>
<span class="k">del</span> <span class="n">vw</span>

<span class="n">vw</span> <span class="o">=</span> <span class="n">pyvw</span><span class="p">.</span><span class="n">vw</span><span class="p">(</span><span class="s">"--cb 4 -i cb.model"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">vw</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="s">'| a b'</span><span class="p">))</span>
</code></pre></div></div>

<p><strong>Output:</strong></p>

<div class="output">
  <p>3</p>
</div>

<p>The <code class="highlighter-rouge">-i</code> argument means input regressor, telling Vowpal Wabbit to load a model from that file instead of starting from scratch.</p>

<h2 id="more-to-explore">More to explore</h2>

<ul>
  <li>Continue to the next tutorial, <a href="cb_simulation.html">Content Personalization with Contextual Bandits</a>.</li>
  <li>Explore more Vowpal Wabbit <a href="../tutorials.html">Tutorials</a>.</li>
  <li>Browse <a href="https://github.com/VowpalWabbit/vowpal_wabbit/wiki/Examples" target="blank">examples on the GitHub wiki</a>.</li>
  <li>Learn various <a href="https://github.com/VowpalWabbit/vowpal_wabbit/wiki/Command-Line-Arguments" target="blank">Vowpal Wabbit commands</a>.</li>
  <li>Review the <a href="https://github.com/VowpalWabbit/vowpal_wabbit/tree/master/python/examples" target="blank">example Python notebooks</a>.</li>
</ul>

        </div>
      </div>
    </div>

    <div class="container bibliography_container">
  <div class="header">
    <h3>
      CITATIONS
    </h3>
    <div class="all_publications_link">
      <a href="/research.html">
        All publications
      </a>
    </div>
  </div>

  <ol class="bibliography"><li><div class="bib_content" id="DBLP:journals/corr/AgarwalBCHLLLMO16">
  Alekh Agarwal and
               Sarah Bird and
               Markus Cozowicz and
               Luong Hoang and
               John Langford and
               Stephen Lee and
               Jiaji Li and
               Dan Melamed and
               Gal Oshri and
               Oswaldo Ribas and
               Siddhartha Sen and
               Alex Slivkins,
  
    <a href="http://arxiv.org/abs/1606.03966">
  
    A Multiworld Testing Decision Service

  
    </a>
  
  (2016)
</div>
<a class="details" href="/bibliography/DBLP_journals/corr/AgarwalBCHLLLMO16.html">Get .bib</a></li>
<li><div class="bib_content" id="DBLP:journals/corr/abs-1003-0146">
  Lihong Li and
               Wei Chu and
               John Langford and
               Robert E. Schapire,
  
    <a href="http://arxiv.org/abs/1003.0146">
  
    A Contextual-Bandit Approach to Personalized News Article Recommendation

  
    </a>
  
  (2010)
</div>
<a class="details" href="/bibliography/DBLP_journals/corr/abs-1003-0146.html">Get .bib</a></li>
<li><div class="bib_content" id="doi:10.1080/01621459.1952.10483446">
   D. G. Horvitz and D. J. Thompson ,
  
    <a href="https://www.tandfonline.com/doi/abs/10.1080/01621459.1952.10483446">
  
    A Generalization of Sampling Without Replacement from a Finite Universe

  
    </a>
  
  (1952)
</div>
<a class="details" href="/bibliography/doi_10.1080/01621459.1952.10483446.html">Get .bib</a></li>
<li><div class="bib_content" id="DBLP:conf/icml/JiangL16">
  Nan Jiang and
               Lihong Li,
  
    <a href="http://proceedings.mlr.press/v48/jiang16.html">
  
    Doubly Robust Off-policy Value Evaluation for Reinforcement Learning

  
    </a>
  
  (2016)
</div>
<a class="details" href="/bibliography/DBLP_conf/icml/JiangL16.html">Get .bib</a></li>
<li><div class="bib_content" id="DBLP:conf/icml/DudikLL11">
  Miroslav Dudı́k and
               John Langford and
               Lihong Li,
  
    <a href="https://icml.cc/2011/papers/554_icmlpaper.pdf">
  
    Doubly Robust Policy Evaluation and Learning

  
    </a>
  
  (2011)
</div>
<a class="details" href="/bibliography/DBLP_conf/icml/DudikLL11.html">Get .bib</a></li>
<li><div class="bib_content" id="bietti2018a">
  Bietti, Alberto and Agarwal, Alekh and Langford, John,
  
    <a href="https://www.microsoft.com/en-us/research/publication/a-contextual-bandit-bake-off-2/">
  
    A Contextual Bandit Bake-off

  
    </a>
  
  (2018)
</div>
<a class="details" href="/bibliography/bietti2018a.html">Get .bib</a></li>
<li><div class="bib_content" id="Karampatziakis:2011:OIW:3020548.3020594">
  Karampatziakis, Nikos and Langford, John,
  
    <a href="http://dl.acm.org/citation.cfm?id=3020548.3020594">
  
    Online Importance Weight Aware Updates

  
    </a>
  
  (2011)
</div>
<a class="details" href="/bibliography/Karampatziakis_2011_OIW_3020548.3020594.html">Get .bib</a></li>
<li><div class="bib_content" id="DBLP:journals/corr/OsbandR15">
  Ian Osband and
               Benjamin Van Roy,
  
    <a href="http://arxiv.org/abs/1507.00300">
  
    Bootstrapped Thompson Sampling and Deep Exploration

  
    </a>
  
  (2015)
</div>
<a class="details" href="/bibliography/DBLP_journals/corr/OsbandR15.html">Get .bib</a></li>
<li><div class="bib_content" id="DBLP:journals/corr/EcklesK14">
  Dean Eckles and
               Maurits Kaptein,
  
    <a href="http://arxiv.org/abs/1410.4009">
  
    Thompson sampling with the online bootstrap

  
    </a>
  
  (2014)
</div>
<a class="details" href="/bibliography/DBLP_journals/corr/EcklesK14.html">Get .bib</a></li>
<li><div class="bib_content" id="DBLP:journals/corr/AgarwalHKLLS14">
  Alekh Agarwal and
               Daniel J. Hsu and
               Satyen Kale and
               John Langford and
               Lihong Li and
               Robert E. Schapire,
  
    <a href="http://arxiv.org/abs/1402.0555">
  
    Taming the Monster: A Fast and Simple Algorithm for Contextual Bandits

  
    </a>
  
  (2014)
</div>
<a class="details" href="/bibliography/DBLP_journals/corr/AgarwalHKLLS14.html">Get .bib</a></li>
<li><div class="bib_content" id="DBLP:journals/corr/abs-1811-04383">
  David Cortes,
  
    <a href="http://arxiv.org/abs/1811.04383">
  
    Adapting multi-armed bandits policies to contextual bandits scenarios

  
    </a>
  
  (2018)
</div>
<a class="details" href="/bibliography/DBLP_journals/corr/abs-1811-04383.html">Get .bib</a></li></ol>
</div>

    <div class="container-fluid footer_container">
  <div class="container">
    <div class="row align-items-center justify-content-between">
      <div class="col">
        Microsoft is a major contributor
      </div>
      <div class="col feedback_col">
        <a
          class="feedback_link"
          href="https://github.com/VowpalWabbit/vowpalwabbit.github.io/issues/new"
          target="_blank"
        >
          Feedback
        </a>
      </div>
    </div>
  </div>
</div>

<script src="/assets/js/citation.js"></script>

    <div class="overlay">
    </div>

    <script src="/assets/js/tutorial.js"></script>
  </body>
</html>
